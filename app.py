# ==========================================================
# QELYON AI STÃœDYO â€” FINAL v8
# Gemini Vision â€¢ Gemini Flash â€¢ Gemini 1.5 Pro â€¢ GPT-4o Hibrit Sistem
# ==========================================================

from __future__ import annotations

import os
import io
import re
import base64
import traceback
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import Literal, Optional

import requests
import streamlit as st
from PIL import Image, ImageOps, ImageFilter, ImageChops, ImageDraw
import google.generativeai as genai
from openai import OpenAI
import mimetypes

# ==========================================================
# ğŸ” API KEYS & CONFIG
# ==========================================================
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", None)
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", None)
WEATHER_API_KEY = st.secrets.get("WEATHER_API_KEY", None)

GPT_MODEL = st.secrets.get("OPENAI_MODEL", "gpt-4o")
GEMINI_TEXT_MODEL = "gemini-1.5-pro"
GEMINI_VISION_MODEL = "gemini-1.5-flash"
DEFAULT_CITY = "Ankara" # Hava durumu iÃ§in varsayÄ±lan ÅŸehir

if not OPENAI_API_KEY:
    st.error("âš ï¸ OPENAI_API_KEY eksik. GPT modlarÄ± Ã§alÄ±ÅŸmaz.")
if not GEMINI_API_KEY:
    st.error("âš ï¸ GEMINI_API_KEY eksik. Gemini modlarÄ± Ã§alÄ±ÅŸmaz.")

# GPT istemcisini sadece anahtar varsa baÅŸlat
GPT = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# Gemini istemcisini konfigÃ¼re et
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    # BoÅŸ da olsa initialize eder, hatalarÄ± yakalarÄ±z
    genai.configure(api_key="")

# ==========================================================
# ğŸ¨ LOGO & FAVICON
# ==========================================================
# Bu dosyalarÄ±n Streamlit uygulamasÄ±nÄ±n dizininde olmasÄ± gereklidir.
LOGO_LIGHT = "QelyonAIblack.png"
LOGO_DARK = "QelyonAIwhite.png"
FAVICON = "favicn.png"

st.set_page_config(
    page_title="Qelyon AI StÃ¼dyo",
    page_icon=FAVICON,
    layout="wide",
)

# ==========================================================
# ğŸ¨ THEME ENGINE
# ==========================================================
def get_theme(is_dark: bool):
    accent = "#6C47FF"
    if is_dark:
        return {
            "bg": "#050509",
            "text": "#FFFFFF",
            "sub": "#A8A8A8",
            "input": "#111111",
            "card": "rgba(255,255,255,0.05)",
            "border": "rgba(255,255,255,0.1)",
            "accent": accent,
        }
    else:
        return {
            "bg": "#F5F5FB",
            "text": "#0F172A",
            "sub": "#444444",
            "input": "#FFFFFF",
            "card": "rgba(255,255,255,0.85)",
            "border": "rgba(0,0,0,0.1)",
            "accent": accent,
        }

def apply_theme_css(t):
    st.markdown(
        f"""
        <style>
        body, .stApp {{
            background: {t['bg']} !important;
            color: {t['text']} !important;
        }}
        .stTextInput>div>div>input,
        textarea {{
            background: {t['input']} !important;
            color: {t['text']} !important;
            border-radius: 12px !important;
            border: 1px solid {t['border']} !important;
        }}
        [data-testid="stChatMessage"] {{
            background: {t['card']};
            border: 1px solid {t['border']};
            border-radius: 14px;
            padding: 10px 14px;
            margin-bottom: 10px;
        }}
        .stButton>button {{
            background: {t['accent']} !important;
            border-radius: 999px !important;
            color: white !important;
            font-weight: 600 !important;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# ==========================================================
# ğŸŒ™ TEMA TOGGLE & UYGULAMA
# ==========================================================
col_a, col_b = st.columns([10,1])
with col_b:
    dark = st.toggle("ğŸŒ™ / â˜€ï¸", value=True)

THEME = get_theme(dark)
apply_theme_css(THEME)

# ==========================================================
# ğŸ§  GLOBAL SESSION SETUP
# ==========================================================
if "app_mode" not in st.session_state:
    st.session_state.app_mode = "ğŸ“¸ StÃ¼dyo Modu"

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "chat_image" not in st.session_state:
    st.session_state.chat_image = None

if "chat_filename" not in st.session_state:
    st.session_state.chat_filename = "dosya"

if "studio_result" not in st.session_state:
    st.session_state.studio_result = None

# ==========================================================
# A2 â€” API CLIENTS â€¢ GEMINI + GPT â€¢ UTILITY FONKSÄ°YONLARI
# ==========================================================

# ---------------------------
# ğŸ”¥ Gemini Client (Google AI)
# ---------------------------
def gemini_text(prompt: str):
    """Gemini 1.5 Pro ile metin Ã¼retimi"""
    if not GEMINI_API_KEY: return "Gemini API AnahtarÄ± eksik."
    try:
        model = genai.GenerativeModel(GEMINI_TEXT_MODEL)
        resp = model.generate_content(prompt)
        return resp.text
    except Exception as e:
        print("Gemini text error:", e)
        return "Gemini ÅŸu anda yanÄ±t veremiyor."

def gemini_vision(prompt: str, image_bytes: bytes):
    """Gemini Vision (Flash) ile gÃ¶rsel analiz"""
    if not GEMINI_API_KEY: return "Gemini API AnahtarÄ± eksik."
    try:
        model = genai.GenerativeModel(GEMINI_VISION_MODEL)
        img_data = {"mime_type": "image/png", "data": image_bytes}
        resp = model.generate_content([prompt, img_data])
        return resp.text
    except Exception as e:
        print("Gemini vision error:", e)
        return "GÃ¶rsel analizinde bir hata oluÅŸtu."

def gemini_generate_image(prompt: str, size="1024x1024"):
    """Gemini Flash Image ile gÃ¶rsel Ã¼retimi"""
    if not GEMINI_API_KEY: return None
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        result = model.generate_image(prompt=prompt, size=size)
        return result._image  # bytes
    except Exception as e:
        print("Gemini image error:", e)
        return None

# ---------------------------
# ğŸ¤– GPT-4o Client
# ---------------------------
def gpt_chat(messages: list[dict], model: str = GPT_MODEL):
    """
    GPT-4o tabanlÄ± sohbet motoru (E-ticaret & DanÄ±ÅŸmanlÄ±k iÃ§in)
    """
    if not GPT: return "GPT API AnahtarÄ± eksik."
    try:
        res = GPT.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.2,
            max_tokens=1500,
        )
        return res.choices[0].message.content
    except Exception as e:
        print("GPT error:", e)
        return "GPT sistemi ÅŸu anda cevap veremiyor."


# ---------------------------
# âš¡ MODEL ROUTER (Mod seÃ§imine gÃ¶re motor)
# ---------------------------
def model_router(mode: str):
    """Moda gÃ¶re kullanÄ±lacak ana motoru belirler."""
    if mode == "GENERAL_CHAT":
        return "gemini"
    if mode in ["ECOM", "CONSULT"]:
        return "gpt"
    return "gemini"


# ==========================================================
# ğŸ“… ZAMAN / TARÄ°H SERVÄ°SLERÄ°
# ==========================================================
def get_tr_time():
    """TÃ¼rkiye yerel saatini dÃ¶ner."""
    try:
        r = requests.get("http://worldtimeapi.org/api/timezone/Europe/Istanbul")
        dt = r.json().get("datetime")
        return datetime.fromisoformat(dt)
    except:
        return datetime.now(ZoneInfo("Europe/Istanbul"))

def time_answer():
    now = get_tr_time()
    return f"BugÃ¼n {now.strftime('%d.%m.%Y')} â€” Saat {now.strftime('%H:%M')}"


# ==========================================================
# ğŸŒ¦ HAVA DURUMU SERVÄ°SÄ°
# ==========================================================
def get_coords(city: str):
    """Åehir adÄ±na gÃ¶re enlem/boylam bulur."""
    if not WEATHER_API_KEY: return None
    try:
        url = (
            f"http://api.openweathermap.org/geo/1.0/direct?"
            f"q={city},TR&limit=1&appid={WEATHER_API_KEY}"
        )
        r = requests.get(url)
        data = r.json()
        if not data:
            return None
        return data[0]["lat"], data[0]["lon"]
    except:
        return None

def get_weather(city: str):
    """Åehir iÃ§in hava durumu bilgisini dÃ¶ner."""
    if not WEATHER_API_KEY: return "Hava durumu API AnahtarÄ± eksik."

    coords = get_coords(city)
    if not coords:
        return f"{city} iÃ§in konum bulunamadÄ±."

    lat, lon = coords
    try:
        url = (
            f"https://api.openweathermap.org/data/2.5/weather?"
            f"lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric&lang=tr"
        )
        r = requests.get(url).json()

        desc = r["weather"][0]["description"].capitalize()
        temp = r["main"]["temp"]
        hum = r["main"]["humidity"]
        wind = r["wind"]["speed"]

        return (
            f"ğŸ“ **{city.title()}**\n"
            f"ğŸŒ¡ï¸ SÄ±caklÄ±k: **{temp:.1f}Â°C**\n"
            f"â˜ï¸ Hava: **{desc}**\n"
            f"ğŸ’§ Nem: **%{hum}**\n"
            f"ğŸƒ RÃ¼zgar: **{wind} m/s**"
        )
    except:
        return "Hava durumu alÄ±namadÄ±."


# ==========================================================
# ğŸ›¡ GÃœVENLÄ°K FÄ°LTRESÄ°
# ==========================================================
BAD_WORDS = [
    r"(?i)orospu", r"(?i)siktir", r"(?i)amk",
    r"(?i)tecavÃ¼z", r"(?i)intihar", r"(?i)bomba yap",
]

def moderate_text(msg: str) -> str | None:
    """Mesaj uygunsuzsa engelle."""
    for pat in BAD_WORDS:
        if re.search(pat, msg):
            return "Bu isteÄŸe gÃ¼venlik nedeniyle yanÄ±t veremiyorum. ğŸ™"
    return None
    
# ==========================================================
# A3 â€” STÃœDYO MODU â€¢ GÃ–RSEL Ä°ÅLEME (GEMINI + LOCAL)
# ==========================================================

# ---------------------------------------
# ğŸ§¼ 1) LOKAL ARKA PLAN KALDIRMA (HQ MASKING)
# ---------------------------------------
def remove_bg_local(image: Image.Image) -> Image.Image:
    """
    ÃœrÃ¼nÃ¼ fotoÄŸraftan lokal threshold + mask algoritmasÄ± ile ayÄ±rÄ±r.
    """
    if image.mode != "RGBA":
        image = image.convert("RGBA")

    gray = image.convert("L")

    # YÃ¼ksek threshold â†’ parlak arka plan silinir
    mask = gray.point(lambda p: 255 if p > 240 else 0)

    result = Image.new("RGBA", image.size)
    result.paste(image, (0, 0), mask)
    return result


# ---------------------------------------
# ğŸ› 2) ÃœRÃœNÃœ KARE TUVALE MERKEZE YERLEÅTÄ°RME
# ---------------------------------------
def center_on_canvas(img: Image.Image, size=1024) -> Image.Image:
    canvas = Image.new("RGBA", (size, size), (0, 0, 0, 0))

    obj = img.copy()
    obj.thumbnail((size * 0.84, size * 0.84), Image.Resampling.LANCZOS)

    x = (size - obj.width) // 2
    y = (size - obj.height) // 2

    canvas.paste(obj, (x, y), obj)
    return canvas


# ---------------------------------------
# ğŸŒ“ 3) PROFESYONEL TEMAS GÃ–LGESÄ°
# ---------------------------------------
def make_contact_shadow(alpha: Image.Image, intensity=150):
    """ÃœrÃ¼nÃ¼n altÄ±na ticari stÃ¼dyo tarzÄ± soft shadow Ã¼retir."""
    a = alpha.convert("L")
    box = a.getbbox()
    if not box:
        return Image.new("L", a.size, 0)

    w = box[2] - box[0]
    h = int((box[3] - box[1]) * 0.22)

    shadow = Image.new("L", (w, h), 0)
    draw = ImageDraw.Draw(shadow)
    draw.ellipse((0, 0, w, h), fill=intensity)
    shadow = shadow.filter(ImageFilter.GaussianBlur(radius=int(h * 0.45)))

    mask = Image.new("L", a.size, 0)
    mask.paste(shadow, (box[0], box[3] - h // 2))
    return mask


# ---------------------------------------
# ğŸŒ« 4) STÃœDYO REFLECTION (Soft Reflection)
# ---------------------------------------
def make_reflection(img: Image.Image, fade=230):
    """Alt kÄ±sÄ±mda premium stÃ¼dyo refleks efekti Ã¼retir."""
    a = img.split()[3]
    box = a.getbbox()
    if not box:
        return Image.new("RGBA", img.size, (0, 0, 0, 0))

    crop = img.crop(box)
    flip = ImageOps.flip(crop)

    grad = Image.linear_gradient("L").resize((1, flip.height))
    grad = grad.point(lambda p: int(p * (fade / 255)))
    grad = grad.resize(flip.size)

    flip.putalpha(grad)

    out = Image.new("RGBA", img.size, (0, 0, 0, 0))
    out.paste(flip, (box[0], box[3] + 6), flip)
    return out


# ---------------------------------------
# ğŸ¨ 5) TEMA KOMPOZÄ°T MOTORU
# ---------------------------------------
def compose_scene(cut: Image.Image, bg_color: str, reflection=True, shadow=True):
    size = 1024
    obj = center_on_canvas(cut, size)
    alpha = obj.split()[3]

    colors = {
        "white": (255, 255, 255, 255),
        "black": (0, 0, 0, 255),
        "beige": (245, 240, 222, 255),
    }

    bg = Image.new("RGBA", (size, size), colors.get(bg_color, (255, 255, 255, 255)))
    final = Image.new("RGBA", (size, size), (0, 0, 0, 0))
    final.alpha_composite(bg)

    if shadow:
        sh_mask = make_contact_shadow(alpha)
        sh = Image.new("RGBA", (size, size), (0, 0, 0, 0))
        sh.putalpha(sh_mask)
        final.alpha_composite(sh)

    if reflection:
        ref = make_reflection(obj)
        final.alpha_composite(ref)

    final.alpha_composite(obj)
    return final


# ---------------------------------------
# âœ¨ 6) GEMINI â€” AI SAHNE OLUÅTURMA
# ---------------------------------------
def gemini_edit_scene(prompt: str, product_image_bytes: bytes):
    """
    ÃœrÃ¼nÃ¼ bozmadan; sadece arka planÄ± AI ile profesyonel olarak yeniden tasarlar.
    Gemini Flash Image modeli ile Ã§alÄ±ÅŸÄ±r.
    """
    if not GEMINI_API_KEY: return None
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")

        img_dict = {
            "mime_type": "image/png",
            "data": product_image_bytes,
        }

        full_prompt = (
            "You are a professional commercial product photographer. "
            "Replace ONLY the background. "
            "Do NOT modify the product (color, texture, geometry). "
            "Generate a clean, studio-grade, elegant scene.\n"
            f"Background style: {prompt}"
        )

        result = model.generate_image(
            prompt=full_prompt,
            image=img_dict,
            size="1024x1024",
        )

        return result._image  # PNG bytes

    except Exception as e:
        print("Gemini Edit Scene Error:", e)
        return None


# ---------------------------------------
# ğŸ— 7) HAZIR TEMA PRESETLERÄ°
# ---------------------------------------
PRESETS = {
    "ğŸ§¹ Åeffaf Arka Plan": "transparent",
    "â¬œ Beyaz Arka Plan": "white",
    "â¬› Siyah Arka Plan": "black",
    "ğŸ¦ Bej Arka Plan": "beige",
    "âœ¨ Profesyonel StÃ¼dyo": "pro",
}

def apply_preset(img: Image.Image, preset: str):
    """
    KullanÄ±cÄ±nÄ±n seÃ§tiÄŸi hazÄ±r temayÄ± uygular.
    """
    cut = remove_bg_local(img)

    if preset == "transparent":
        return cut

    if preset == "white":
        return compose_scene(cut, "white", reflection=False)

    if preset == "black":
        return compose_scene(cut, "black", reflection=False)

    if preset == "beige":
        return compose_scene(cut, "beige", reflection=False)

    if preset == "pro":
        return compose_scene(cut, "white", reflection=True)

    return cut
    
# ==========================================================
# A8 â€” ğŸ“„ PDF & ğŸ–¼ GÃ¶rsel OCR + Belge Analiz Motoru (Gemini 1.5 Pro)
# ==========================================================

def guess_mime_type(filename: str, default: str = "application/octet-stream") -> str:
    """Dosya adÄ±na gÃ¶re MIME type tahmini."""
    mime, _ = mimetypes.guess_type(filename)
    return mime or default


def gemini_analyze_document(
    file_bytes: bytes,
    filename: str,
    user_instruction: str = "Bu dosyayÄ± profesyonelce Ã¶zetle ve Ã¶nemli maddeleri Ã§Ä±kar.",
) -> str:
    """PDF, PNG, JPG gibi dosyalarÄ± Gemini 1.5 Pro ile okur (OCR + anlamlandÄ±rma)."""

    if not GEMINI_API_KEY: return "Gemini API AnahtarÄ± eksik."
    if not file_bytes: return "Dosya iÃ§eriÄŸi boÅŸ gÃ¶rÃ¼nÃ¼yor."

    mime_type = guess_mime_type(filename)

    file_part = {
        "mime_type": mime_type,
        "data": file_bytes,
    }

    prompt = (
        "Sen Qelyon AI dokÃ¼man analiz uzmanÄ±sÄ±n. "
        "PDF, resim veya taranmÄ±ÅŸ belge iÃ§eriÄŸini dikkatlice okur, "
        "Ã¶nemli kÄ±sÄ±mlarÄ± net ve anlaÅŸÄ±lÄ±r bir ÅŸekilde Ã¶zetlersin. "
        "Maddeler halinde kritik baÅŸlÄ±klarÄ± ve aksiyon alÄ±nabilir Ã¶nerileri Ã§Ä±kar.\n\n"
        f"KullanÄ±cÄ± talimatÄ±: {user_instruction}"
    )

    try:
        model = genai.GenerativeModel(GEMINI_TEXT_MODEL)
        response = model.generate_content([prompt, file_part])

        if hasattr(response, "text") and response.text:
            return response.text.strip()

        return "Dosya analiz edildi fakat metin cevap Ã¼retilemedi."
    except Exception as e:
        print("Gemini Document Analyze Error:", e)
        return "Belge analizinde bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar dene."


def analyze_uploaded_file_in_chat(user_message: str) -> str:
    """
    General Chat iÃ§inde:
      - KullanÄ±cÄ± PDF / gÃ¶rsel yÃ¼klediyse
      - 'bu pdfi Ã¶zetle', 'bu gÃ¶rseli analiz et', 'bu dosyayÄ± incele' gibi bir ÅŸey yazdÄ±ysa
    â†’ Bu fonksiyon Ã§aÄŸrÄ±lÄ±p Gemini belge analiz Ã§alÄ±ÅŸtÄ±rÄ±labilir.
    """
    if st.session_state.chat_image is None:
        return ""

    triggers = [
        "pdfi Ã¶zetle", "pdf'i Ã¶zetle", "pdf Ã¶zetle",
        "bu dosyayÄ± Ã¶zetle", "bu dosyayÄ± analiz et", "belgeyi analiz et",
        "dokÃ¼manÄ± analiz et", "bu gÃ¶rseli analiz et", "bu resmi analiz et",
        "dosyayÄ± incele",
    ]

    if not any(t in user_message.lower() for t in triggers):
        # KullanÄ±cÄ±nÄ±n isteÄŸi doÄŸrudan dokÃ¼man analizi deÄŸilse, normal chat akÄ±ÅŸÄ± devam eder.
        return ""

    # Belge analizi isteniyor
    file_bytes = st.session_state.chat_image
    filename = st.session_state.chat_filename
    user_instruction = user_message # KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± talimat olarak kullan

    result = gemini_analyze_document(file_bytes, filename, user_instruction)
    return result

# ==========================================================
# A4 â€” GENEL CHAT MOTORU (GEMINI 1.5 PRO)
# ==========================================================
IMAGE_TRIGGER_WORDS = [
    "gÃ¶rsel oluÅŸtur", "resim oluÅŸtur", "foto Ã¼ret",
    "bir gÃ¶rsel Ã§iz", "image create", "generate image",
    "bana bir tasarÄ±m yap", "logo yap", "arka plan Ã¼ret",
]

def is_image_generation_request(msg: str) -> bool:
    """KullanÄ±cÄ±nÄ±n gÃ¶rsel Ã¼retim isteÄŸi yapÄ±p yapmadÄ±ÄŸÄ±nÄ± kontrol eder."""
    msg = msg.lower()
    return any(t in msg for t in IMAGE_TRIGGER_WORDS)


def gemini_general_chat(user_message: str, user_image: bytes | None):
    """
    Genel Chat (ğŸ’¬) iÃ§in tam sohbet motoru: Gemini 1.5 Pro metin ve vision.
    """
    if not GEMINI_API_KEY: return "Gemini API AnahtarÄ± eksik."

    try:
        # --- 1) Sohbet geÃ§miÅŸini Gemini formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r ---
        history = []
        for msg in st.session_state.chat_history[-25:]:
            if msg["role"] == "user":
                history.append({
                    "role": "user",
                    "parts": [msg["content"]]
                })
            elif msg["role"] == "assistant" and msg["content"] != "(GÃ¶rsel Ã¼retildi)":
                history.append({
                    "role": "model",
                    "parts": [msg["content"]]
                })

        # --- 2) KullanÄ±cÄ±nÄ±n yeni mesajÄ± ---
        new_parts = [{"text": user_message}]

        # --- 3) EÄŸer gÃ¶rsel yÃ¼klÃ¼yse ekle ---
        if user_image:
            # BurasÄ± sadece gÃ¶rsel yÃ¼klenmiÅŸse tetiklenir (AynÄ± anda PDF yÃ¼klenmiÅŸse de)
            # Analiz iÃ§in sadece gÃ¶rsel part'Ä± eklenir
            if not st.session_state.chat_filename.lower().endswith('.pdf'):
                new_parts.append({
                    "inline_data": {
                        "mime_type": "image/png", # VarsayÄ±lan olarak png kabul edilir
                        "data": base64.b64encode(user_image).decode("utf-8")
                    }
                })
        
        user_turn = {
            "role": "user",
            "parts": new_parts
        }

        full_prompt = history + [user_turn]

        # --- 4) Gemini model ---
        model = genai.GenerativeModel("gemini-1.5-pro")
        response = model.generate_content(full_prompt)

        if hasattr(response, "text"):
            return response.text

        return "Bir yanÄ±t Ã¼retemedim."

    except Exception as e:
        print("General Chat Error:", e)
        return "ğŸ’¥ ÃœzgÃ¼nÃ¼m, ÅŸu anda genel chat yanÄ±t veremiyor."


def handle_general_chat(user_message: str):
    """Genel Chat UI â†’ Motor baÄŸlayÄ±cÄ±."""

    # 1) KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe kaydet
    st.session_state.chat_history.append({
        "role": "user",
        "content": user_message
    })

    with st.chat_message("user"):
        st.write(user_message)

    # 2) GÃ¶rsel Ã¼retim isteÄŸi
    if is_image_generation_request(user_message):
        with st.chat_message("assistant"):
            st.write("ğŸ¨ GÃ¶rsel oluÅŸturuluyor...")
            img_bytes = gemini_generate_image(user_message)

            if img_bytes:
                st.image(img_bytes, caption="âœ¨ Gemini 1.5 Flash tarafÄ±ndan Ã¼retildi", width=350)
                ai_answer = "(GÃ¶rsel Ã¼retildi)" # GeÃ§miÅŸe kÄ±sa not
            else:
                ai_answer = "âš ï¸ GÃ¶rsel oluÅŸturulamadÄ±, lÃ¼tfen tekrar deneyin."
            
            if ai_answer != "(GÃ¶rsel Ã¼retildi)":
                st.write(ai_answer)

    # 3) Normal metin + gÃ¶rsel analizi sohbeti (GÃ¶rsel Ã¼retim istenmediyse)
    else:
        with st.chat_message("assistant"):
            with st.spinner("Qelyon AI dÃ¼ÅŸÃ¼nÃ¼yor..."):
                ai_answer = gemini_general_chat(
                    user_message,
                    st.session_state.chat_image
                )
                st.write(ai_answer)

    st.session_state.chat_history.append({
        "role": "assistant",
        "content": ai_answer
    })


# ==========================================================
# A5 â€” GPT SYSTEM TALÄ°MATI (E-Ticaret + DanÄ±ÅŸmanlÄ±k Persona)
# ==========================================================

def build_system_talimati(profile: Literal["ecom", "consult"]) -> str:

    if profile == "ecom":
        return """
Sen Qelyon AI'nÄ±n E-Ticaret UzmanÄ± modundasÄ±n.
GÃ¶revlerin:
1) ÃœrÃ¼n aÃ§Ä±klamasÄ± (SEO uyumlu, profesyonel, ikna edici)
2) ÃœrÃ¼nÃ¼n Ã¶ne Ã§Ä±kan 5 faydasÄ±nÄ± yaz
3) Kutu iÃ§eriÄŸi oluÅŸtur
4) Hedef kitle analizi yap
5) KullanÄ±m Ã¶nerileri Ã¼ret
6) ÃœrÃ¼ne Ã¶zel CTA (satÄ±n almaya yÃ¶nlendiren)
7) ÃœrÃ¼n gÃ¶rseli/PDF varsa analiz et, metne entegre et
8) ÃœrÃ¼n iÃ§in A/B testli baÅŸlÄ±k varyantlarÄ± oluÅŸtur
9) Trendyol iÃ§in akÄ±llÄ± etiket algoritmasÄ± Ã§alÄ±ÅŸtÄ±r
10) Fiyat psikolojisi optimizasyonu Ã¶nerileri ver
11) ÃœrÃ¼n varyantlarÄ±nÄ± belirle (renk, beden, kapasite, model)
12) MÃ¼ÅŸteri yorumlarÄ±nÄ± analiz edip memnuniyet/ÅŸikayet temalarÄ±nÄ± Ã§Ä±kar
13) Sosyal medya reklam metinleri Ã¼ret (Meta, TikTok, Instagram)
14) Marka hikÃ¢yesi yaz
15) Ä°Ã§erikleri TÃ¼rkÃ§e ve profesyonel bir tonda oluÅŸtur

DÄ°KKAT:
- Gereksiz uzunluk yok, doÄŸrudan ticari fayda odaklÄ± yaz.
- ÃœrÃ¼n gÃ¶rseli/PDF varsa mutlaka analiz ederek davran.
- Qelyon AI kimliÄŸinden sapma: YASAK.
"""
        
    # ------------------------------------------------------

    if profile == "consult":
        return """
Sen Qelyon AI'nÄ±n DanÄ±ÅŸmanlÄ±k UzmanÄ± modundasÄ±n.
UzmanlÄ±k alanlarÄ±n:
- Ä°ÅŸ geliÅŸtirme
- Marka konumlandÄ±rma
- Finansal iyileÅŸtirme
- Operasyonel verimlilik
- Pazarlama stratejisi
- Dijital dÃ¶nÃ¼ÅŸÃ¼m
- SWOT + rakip analizi
- KPI Ã§Ä±karÄ±mÄ±
- Yol haritasÄ± oluÅŸturma

GÃ¶revlerin:
1) KullanÄ±cÄ±nÄ±n iÅŸ modelini analiz et
2) SektÃ¶re Ã¶zel strateji Ã¶ner
3) KPI ve hedef sistemi Ã§Ä±kar
4) SWOT analizi yap
5) AdÄ±m adÄ±m geliÅŸim planÄ± oluÅŸtur
6) GerektiÄŸinde gelir modeli Ã¶ner
7) Ä°ÅŸ fikri validasyonu yap
8) PDF veya dokÃ¼man varsa analiz et, Ã§Ä±ktÄ±ya dahil et
9) GÃ¶rsel varsa iÃ§gÃ¶rÃ¼ Ã¼ret (Ã¶r: maÄŸaza fotoÄŸrafÄ±, Ã¼rÃ¼n, afiÅŸ)

Kimlik:
â€œQelyon AI olarak, profesyonel danÄ±ÅŸmanlÄ±k ve veri destekli iÃ§gÃ¶rÃ¼lerle iÅŸ hedeflerine ulaÅŸmanÄ± hÄ±zlandÄ±rÄ±yorum.â€

Tarz:
- Kesin
- Analitik
- Stratejik
- Gereksiz hikÃ¢ye yok, tamamen iÅŸ odaklÄ±.
"""

    return "Qelyon AI sistem talimatÄ± uygulanamadÄ±."

# ==========================================================
# A5 â€” IDENTITY INTERCEPTOR (Qelyon AI KÄ°MLÄ°K SÄ°STEMÄ°)
# ==========================================================

def custom_identity_interceptor(msg: str) -> Optional[str]:
    """Kimlik veya tanÄ±ÅŸma sorularÄ±na cevap verir."""
    msg_low = msg.lower()

    if any(x in msg_low for x in ["kimsin", "sen neysin", "kim yapt", "kim geliÅŸtirdi"]):
        return "Ben Qelyon AI'yÄ±m. Hibrit bir mimari kullanÄ±yorum: Gemini Vision + GPT-4o. Qelyon AI ekibi tarafÄ±ndan geliÅŸtirildim."

    if "openai" in msg_low or "gpt" in msg_low:
        return "Ben Qelyon AI'yÄ±m. GPT-4o teknolojisini kullanÄ±yorum ancak Qelyon AI'ya Ã¶zel yeteneklerle geniÅŸletildim. Hibrit bir sistemim."

    if "ne iÅŸ yaparsÄ±n" in msg_low or "gÃ¶revin ne" in msg_low:
        return "Qelyon AI olarak, profesyonel danÄ±ÅŸmanlÄ±k ve veri destekli iÃ§gÃ¶rÃ¼lerle iÅŸ hedeflerine ulaÅŸmanÄ± hÄ±zlandÄ±rÄ±yorum."

    return None

# ==========================================================
# A5 â€” UTILITY INTERCEPTOR (Zaman + Hava)
# ==========================================================

def custom_utility_interceptor(msg: str) -> Optional[str]:
    """Saat ve hava durumu gibi genel bilgilere cevap verir."""
    m = msg.lower()

    # Saat
    if "saat" in m and ("kaÃ§" in m or "?" in m):
        return time_answer()

    # Hava durumu
    if "hava" in m or "hava durumu" in m:
        return get_weather(DEFAULT_CITY)

    return None

# ==========================================================
# A5 â€” GPT-4o ANA ASÄ°STAN MOTORU
# ==========================================================

def gpt_assistant(profile: Literal["ecom", "consult"], user_message: str) -> str:
    if not GPT: return "GPT API AnahtarÄ± eksik."

    try:
        system_msg = build_system_talimati(profile)
        
        # KullanÄ±cÄ±nÄ±n mesajÄ±nÄ± ve yÃ¼klÃ¼ dosya bilgisini system'e ekle
        user_content = [{"type": "text", "text": user_message}]
        
        # EÄŸer chat_image yÃ¼klÃ¼ ise
        if st.session_state.chat_image:
            # GÃ¶rsel iÃ§in
            if not st.session_state.chat_filename.lower().endswith('.pdf'):
                encoded_image = base64.b64encode(st.session_state.chat_image).decode('utf-8')
                user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/png;base64,{encoded_image}"
                    }
                })
            # PDF iÃ§in metinsel olarak referans ver
            else:
                pdf_analysis = gemini_analyze_document(
                    st.session_state.chat_image, 
                    st.session_state.chat_filename, 
                    "Bu PDF/dokÃ¼man iÃ§eriÄŸini Ã¶zetle."
                )
                system_msg += f"\n\n[EK DOSYA ANALÄ°ZÄ° ({st.session_state.chat_filename})]:\n{pdf_analysis}"


        msgs = [{"role": "system", "content": system_msg}]
        
        # GeÃ§miÅŸteki metin mesajlarÄ±nÄ± ekle (Ã‡oklu-modal mesajlar GPT-4o'da farklÄ± ele alÄ±nÄ±r)
        for m in st.session_state.chat_history[-10:]: # Sadece metin mesajlarÄ±nÄ± ekle
             if m["role"] == "user" and m["content"] == user_message:
                 continue # Åu anki mesajÄ± eklememek iÃ§in

             msgs.append({
                 "role": m["role"],
                 "content": m["content"]
             })

        # En son kullanÄ±cÄ± mesajÄ±nÄ± ekle (iÃ§inde gÃ¶rsel/pdf bilgisi de var)
        msgs.append({
            "role": "user", 
            "content": user_content
        })


        res = GPT.chat.completions.create(
            model="gpt-4o",
            messages=msgs,
            temperature=0.3,
            max_tokens=1800,
        )

        return res.choices[0].message.content

    except Exception as e:
        print("GPT Assist Error:", e)
        return "Åu anda GPT-4o yanÄ±t veremiyor. BirkaÃ§ dakika sonra tekrar deneyin."

# ==========================================================
# A5 â€” GPT ASÄ°STANI UI ROUTER
# ==========================================================

def handle_gpt_assistant(profile: Literal["ecom", "consult"], user_message: str):
    """GPT AsistanlarÄ± iÃ§in ana iÅŸleyici (ECOM ve CONSULT)."""
    if not user_message:
        return

    # 1) KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe kaydet
    st.session_state.chat_history.append({"role": "user", "content": user_message})
    with st.chat_message("user"):
        st.write(user_message)

    # 2) Interceptor (Kimlik/YardÄ±mcÄ±) kontrolÃ¼
    ident = custom_identity_interceptor(user_message)
    util = custom_utility_interceptor(user_message)

    if ident:
        answer = ident
    elif util:
        answer = util
    else:
        # 3) Normal GPT-4o cevabÄ±
        with st.chat_message("assistant"):
            with st.spinner("Qelyon AI dÃ¼ÅŸÃ¼nÃ¼yor..."):
                answer = gpt_assistant(profile, user_message)
    
    with st.chat_message("assistant"): st.write(answer)
    st.session_state.chat_history.append({"role": "assistant", "content": answer})


# ==========================================================
# A6 â€” MOD SEÃ‡Ä°MÄ° + GENEL CHAT (Gemini) + GPT ASÄ°STAN UI
# ==========================================================

# ---------------------------------------------
# ğŸ’¬ 2) GENEL CHAT UI (Gemini 1.5 Pro + Flash)
# ---------------------------------------------
def general_chat_ui():
    st.markdown("### ğŸ’¬ Qelyon AI â€” Genel Chat (Gemini)")
    st.caption("Gemini 1.5 Pro & Flash ile metin, gÃ¶rsel analizi ve gÃ¶rsel oluÅŸturma yapabilirsin.")

    # --- Mesaj geÃ§miÅŸi ---
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            if msg["content"] != "(GÃ¶rsel Ã¼retildi)": # GÃ¶rsel Ã¼retim notunu gÃ¶sterme
                st.write(msg["content"])

    # --- Dosya yÃ¼kleme (gÃ¶rsel / pdf) ---
    upload = st.file_uploader(
        "GÃ¶rsel / PDF yÃ¼kle (isteÄŸe baÄŸlÄ±)",
        type=["png", "jpg", "jpeg", "webp", "pdf"],
        key="general_upload",
    )

    if upload is not None:
        file_bytes = upload.read()
        st.session_state.chat_image = file_bytes
        st.session_state.chat_filename = upload.name
        st.success(f"ğŸ“ Dosya yÃ¼klendi: {upload.name}! MesajÄ±nda bu dosyadan bahsedebilirsin.")
    elif "general_upload" in st.session_state and st.session_state.general_upload is None:
         st.session_state.chat_image = None
         st.session_state.chat_filename = "dosya"

    # --- KullanÄ±cÄ± mesajÄ± ---
    user_msg = st.chat_input("MesajÄ±nÄ± yaz...")

    if user_msg:
        # GÃ¼venlik filtresi
        mod = moderate_text(user_msg)
        if mod:
            st.session_state.chat_history.append({"role": "user", "content": user_msg})
            with st.chat_message("user"): st.write(user_msg)
            with st.chat_message("assistant"): st.write(mod)
            st.session_state.chat_history.append({"role": "assistant", "content": mod})
            return

        # DokÃ¼man analizi tetikleniyor mu?
        doc_answer = analyze_uploaded_file_in_chat(user_msg)
        if doc_answer:
            st.session_state.chat_history.append({"role": "user", "content": user_msg})
            with st.chat_message("user"): st.write(user_msg)
            with st.chat_message("assistant"): st.write(doc_answer)
            st.session_state.chat_history.append({"role": "assistant", "content": doc_answer})
            return

        # Normal Gemini general chat akÄ±ÅŸÄ±
        handle_general_chat(user_msg)


# ---------------------------------------------
# ğŸ›’ 3) E-TÄ°CARET ASÄ°STANI UI (GPT-4o)
# ---------------------------------------------
def ecom_chat_ui():
    st.markdown("### ğŸ›’ Qelyon AI â€” E-Ticaret AsistanÄ± (GPT-4o)")
    st.caption("ÃœrÃ¼n aÃ§Ä±klamalarÄ±, SEO baÅŸlÄ±klar, etiketler ve kampanya metinleri iÃ§in kullan.")

    # Mesaj geÃ§miÅŸi
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Ä°steÄŸe baÄŸlÄ± gÃ¶rsel / pdf yÃ¼kleme
    upload = st.file_uploader(
        "ÃœrÃ¼n gÃ¶rseli veya PDF yÃ¼kle (opsiyonel)",
        type=["png", "jpg", "jpeg", "webp", "pdf"],
        key="ecom_upload",
    )
    if upload is not None:
        st.session_state.chat_image = upload.read()
        st.session_state.chat_filename = upload.name
        st.success(f"ğŸ“ Dosya yÃ¼klendi: {upload.name}! ÃœrÃ¼n aÃ§Ä±klamasÄ±nda bu dosyaya referans verebilirsin.")
    elif "ecom_upload" in st.session_state and st.session_state.ecom_upload is None:
         st.session_state.chat_image = None
         st.session_state.chat_filename = "dosya"

    user_msg = st.chat_input("ÃœrÃ¼n veya ihtiyacÄ±nÄ± anlat...")

    if user_msg:
        handle_gpt_assistant("ecom", user_message=user_msg)


# ---------------------------------------------
# ğŸ’¼ 4) DANIÅMANLIK ASÄ°STANI UI (GPT-4o)
# ---------------------------------------------
def consult_chat_ui():
    st.markdown("### ğŸ’¼ Qelyon AI â€” DanÄ±ÅŸmanlÄ±k AsistanÄ± (GPT-4o)")
    st.caption("Ä°ÅŸ modeli, bÃ¼yÃ¼me stratejisi, KPI/OKR ve operasyonel verimlilik iÃ§in kullan.")

    # Mesaj geÃ§miÅŸi
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Opsiyonel dokÃ¼man/gÃ¶rsel yÃ¼kleme
    upload = st.file_uploader(
        "Rapor, PDF veya gÃ¶rsel yÃ¼kle (opsiyonel)",
        type=["png", "jpg", "jpeg", "webp", "pdf"],
        key="consult_upload",
    )
    if upload is not None:
        st.session_state.chat_image = upload.read()
        st.session_state.chat_filename = upload.name
        st.success(f"ğŸ“ Dosya yÃ¼klendi: {upload.name}! Analiz yaparken bu dosyadan bahsedebilirsin.")
    elif "consult_upload" in st.session_state and st.session_state.consult_upload is None:
         st.session_state.chat_image = None
         st.session_state.chat_filename = "dosya"

    user_msg = st.chat_input("Ä°ÅŸini veya sorunu anlat...")

    if user_msg:
        handle_gpt_assistant("consult", user_message=user_msg)


# ==========================================================
# A7 â€” ğŸ“¸ QELYON AI STÃœDYO MODU (FINAL v8)
# ==========================================================

def render_studio_mode():
    st.markdown("## ğŸ“¸ Qelyon AI â€” StÃ¼dyo Modu")
    st.caption("ÃœrÃ¼nlerin iÃ§in profesyonel arka plan, Ä±ÅŸÄ±k, gÃ¶lge ve sahne oluÅŸturma modu.")

    # ------------------------
    # 1) GÃ¶rsel yÃ¼kleme alanÄ±
    # ------------------------
    uploaded = st.file_uploader(
        "ğŸ¨ ÃœrÃ¼n fotoÄŸrafÄ±nÄ± yÃ¼kle",
        type=["png", "jpg", "jpeg", "webp"],
        key="studio_upload",
    )

    if uploaded is not None:
        img = Image.open(uploaded).convert("RGBA")
        st.image(img, caption="YÃ¼klenen GÃ¶rsel", width=350)
        st.session_state.studio_source = img
    
    # EÄŸer gÃ¶rsel yoksa ve Ã¶nceki yÃ¼kleme durumunda gÃ¶rsel yoksa devam etme
    if "studio_source" not in st.session_state or st.session_state.studio_source is None:
        st.info("BaÅŸlamak iÃ§in bir Ã¼rÃ¼n gÃ¶rseli yÃ¼kle.")
        return

    img = st.session_state.studio_source

    col_presets, col_ai = st.columns(2)

    with col_presets:
        # ------------------------
        # 2) Preset seÃ§imleri
        # ------------------------
        st.markdown("### ğŸ› HazÄ±r Temalar")

        preset_name = st.selectbox(
            "Bir tema seÃ§:",
            list(PRESETS.keys()),
            index=0,
            key="studio_preset_select"
        )
        
        # 4) Ä°ÅŸlem butonu
        apply_preset_btn = st.button("ğŸ¨ TemayÄ± Uygula", use_container_width=True)


    with col_ai:
        # ------------------------
        # 3) Profesyonel AI sahne oluÅŸturma
        # ------------------------
        st.markdown("### âœ¨ AI Sahne OluÅŸturma (Opsiyonel)")

        ai_prompt = st.text_area(
            "Profesyonel sahne (Ã¶rn: 'lÃ¼x stÃ¼dyo Ä±ÅŸÄ±ÄŸÄ±, soft shadow, minimal set')",
            placeholder="Buraya yazarsan Gemini Vision Ã¶zel sahne oluÅŸturur.",
            key="ai_prompt_text",
            height=100
        )

        generate_ai_scene = st.button("âœ¨ AI Sahne OluÅŸtur (Gemini Vision)", type="primary", use_container_width=True)

    
    result = None

    # ------------------------
    # 5) TemayÄ± uygula (lokal render)
    # ------------------------
    if apply_preset_btn:
        with st.spinner("TemanÄ±z iÅŸleniyor..."):
            result = apply_preset(img, PRESETS[preset_name])
            st.session_state.studio_result = result

    # ------------------------
    # 6) AI sahne oluÅŸtur
    # ------------------------
    if generate_ai_scene and ai_prompt.strip():
        with st.spinner("AI sahne oluÅŸturuluyor... (Gemini Vision)"):
            buffered = io.BytesIO()
            img.save(buffered, format="PNG")
            bytes_img = buffered.getvalue()

            ai_img_bytes = gemini_edit_scene(ai_prompt, bytes_img)

            if ai_img_bytes:
                result = Image.open(io.BytesIO(ai_img_bytes)).convert("RGBA")
                st.session_state.studio_result = result
            else:
                st.error("AI sahne oluÅŸturulamadÄ±. LÃ¼tfen yeniden deneyin.")

    # ------------------------
    # 7) SonuÃ§ gÃ¶rÃ¼ntÃ¼leme
    # ------------------------
    if st.session_state.studio_result is not None:
        st.divider()
        st.markdown("### ğŸ“¤ Ã‡Ä±ktÄ±")

        st.image(st.session_state.studio_result, width=512)

        # Ä°ndirilebilir link
        output_buffer = io.BytesIO()
        # st.session_state.studio_result.save(output_buffer, format="PNG")
        
        # EÄŸer sonuÃ§ AI'dan geldiyse (JPG/WebP olabilir), PNG olarak kaydetmeyi deneyin
        if st.session_state.studio_result.mode == 'P':
             st.session_state.studio_result.convert('RGB').save(output_buffer, format="PNG")
        else:
             st.session_state.studio_result.save(output_buffer, format="PNG")
             
        st.download_button(
            "ğŸ“¥ Ã‡Ä±ktÄ±yÄ± Ä°ndir (PNG)",
            data=output_buffer.getvalue(),
            file_name="qelyon_studio_output.png",
            mime="image/png",
            use_container_width=True
        )


# ==========================================================
# ğŸ–¼ï¸ B1 â€” ANA UYGULAMA YAPISI (MAIN APP)
# ==========================================================

def render_main_logo(dark_mode: bool):
    """Koyu/aÃ§Ä±k moda gÃ¶re logo ve baÅŸlÄ±k hizalamasÄ± ve mod butonlarÄ±."""
    logo_path = LOGO_DARK if dark_mode else LOGO_LIGHT
    
    col_logo, col_title = st.columns([1, 6])
    with col_logo:
        # Logo dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
        if os.path.exists(logo_path):
             # Base64 ile kÃ¼Ã§Ã¼k bir logo render et
            st.markdown(f'<img src="data:image/png;base64,{base64.b64encode(open(logo_path, "rb").read()).decode()}" style="height: 50px; margin-top: 10px;">', unsafe_allow_html=True)
        else:
            st.markdown(f"<h1 style='color: {THEME['accent']}; margin-top: 10px; font-size: 30px;'>QALYON</h1>", unsafe_allow_html=True)

    with col_title:
        st.markdown(f"<h1 style='color: {THEME['accent']}; margin-top: 10px;'>Qelyon AI StÃ¼dyo</h1>", unsafe_allow_html=True)
    
    st.markdown(
        "<div style='margin-bottom: 20px;'></div>",
        unsafe_allow_html=True
    )

    # 4 Modun butonlarÄ±
    mode_cols = st.columns(4)
    modes = {
        "ğŸ“¸ StÃ¼dyo Modu": "ğŸ“¸ StÃ¼dyo (Gemini Vision)",
        "GENERAL_CHAT": "ğŸ’¬ Genel Chat (Gemini 1.5 Pro)",
        "ECOM": "ğŸ›’ E-Ticaret AsistanÄ± (GPT-4o)",
        "CONSULT": "ğŸ’¼ DanÄ±ÅŸmanlÄ±k AsistanÄ± (GPT-4o)",
    }
    
    for i, (key, label) in enumerate(modes.items()):
        with mode_cols[i]:
            if st.button(
                label,
                use_container_width=True,
                type="primary" if st.session_state.app_mode == key else "secondary",
                key=f"mode_btn_{i}"
            ):
                # Mod deÄŸiÅŸimi yapÄ±ldÄ±ÄŸÄ±nda chat geÃ§miÅŸini temizle
                if key != st.session_state.app_mode:
                    st.session_state.chat_history = []
                    st.session_state.chat_image = None
                    st.session_state.chat_filename = "dosya"
                    
                st.session_state.app_mode = key
                st.rerun()

    st.divider()

def render_footer():
    """Ä°stenilen footer bilgisini sayfanÄ±n en altÄ±na sabitleyen HTML/CSS."""
    footer_html = f"""
    <style>
    .footer {{
        position: fixed;
        left: 0;
        bottom: 0;
        width: 100%;
        background-color: {THEME['bg']};
        color: {THEME['sub']};
        text-align: center;
        padding: 10px;
        font-size: 14px;
        border-top: 1px solid {THEME['border']};
        z-index: 100;
    }}
    </style>
    <div class="footer">
        Qelyon AI Â© 2025 â€” Developed by Alper
    </div>
    """
    st.markdown(footer_html, unsafe_allow_html=True)


def main_app_router():
    """Ana akÄ±ÅŸÄ± yÃ¶neten router."""
    
    render_main_logo(dark) # Tema toggl'Ä±nÄ± kullan

    # Mod seÃ§imine gÃ¶re iÃ§eriÄŸi yÃ¶nlendir
    if st.session_state.app_mode == "ğŸ“¸ StÃ¼dyo Modu":
        render_studio_mode()
    elif st.session_state.app_mode == "GENERAL_CHAT":
        general_chat_ui()
    elif st.session_state.app_mode == "ECOM":
        ecom_chat_ui()
    elif st.session_state.app_mode == "CONSULT":
        consult_chat_ui()

    render_footer()

if __name__ == "__main__":
    main_app_router()
