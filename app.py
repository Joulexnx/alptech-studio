# ==========================================================
# QELYON AI STÃœDYO â€” v5.0
# Gemini Vision â€¢ Gemini 1.5 Flash/Pro â€¢ GPT-4o Hibrit Sistem
# ==========================================================

from __future__ import annotations

import base64
import io
import traceback
import re
import requests
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import Literal, Optional

import streamlit as st
from PIL import Image, ImageOps
from google import generativeai as genai
from openai import OpenAI

from __future__ import annotations

import os
import io
import re
import base64
import traceback
from datetime import datetime
from io import BytesIO
from typing import Literal
from zoneinfo import ZoneInfo

import requests
import streamlit as st
from PIL import Image, ImageOps, ImageFilter, ImageChops, ImageDraw

# ==========================================================
# ğŸ” SECRETS & API KEYS
# ==========================================================
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", None)
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", None)

if not OPENAI_API_KEY:
    st.error("âš ï¸ OPENAI_API_KEY eksik. GPT tabanlÄ± modlar Ã§alÄ±ÅŸmayacaktÄ±r.")

if not GEMINI_API_KEY:
    st.error("âš ï¸ GEMINI_API_KEY eksik. Gemini tabanlÄ± modlar Ã§alÄ±ÅŸmayacaktÄ±r.")

# VarsayÄ±lan GPT modeli
GPT_MODEL = st.secrets.get("OPENAI_MODEL", "gpt-4o")

# Gemini modelleri
GEMINI_TEXT_MODEL = "gemini-1.5-pro"
GEMINI_VISION_MODEL = "gemini-1.5-flash"

# ==========================================================
# ğŸŒ WEATHER API
# ==========================================================
WEATHER_API_KEY = st.secrets.get(
    "WEATHER_API_KEY", "5f9ee20a060a62ba9cb79d4a048395d9"
)
DEFAULT_CITY = "Ä°stanbul"

# ==========================================================
# ğŸ¨ LOGO & FAVICON
# ==========================================================
LOGO_LIGHT = "QelyonAIblack.png"
LOGO_DARK = "QelyonAIwhite.png"
FAVICON = "favicn.png"

st.set_page_config(
    page_title="Qelyon AI StÃ¼dyo",
    page_icon=FAVICON,
    layout="wide",
)

# ==========================================================
# ğŸ¨ THEME ENGINE
# ==========================================================
def get_theme(is_dark: bool):
    accent = "#6C47FF"
    if is_dark:
        return {
            "bg": "#050509",
            "text": "#FFFFFF",
            "sub": "#A8A8A8",
            "input": "#111",
            "card": "rgba(255,255,255,0.05)",
            "border": "rgba(255,255,255,0.1)",
            "accent": accent,
        }
    else:
        return {
            "bg": "#F5F5FB",
            "text": "#0F172A",
            "sub": "#444",
            "input": "#fff",
            "card": "rgba(255,255,255,0.85)",
            "border": "rgba(0,0,0,0.1)",
            "accent": accent,
        }

def apply_theme_css(t):
    st.markdown(
        f"""
        <style>
        body, .stApp {{
            background: {t['bg']} !important;
            color: {t['text']} !important;
        }}
        .stTextInput>div>div>input,
        textarea {{
            background: {t['input']} !important;
            color: {t['text']} !important;
            border-radius: 12px !important;
            border: 1px solid {t['border']} !important;
        }}
        [data-testid="stChatMessage"] {{
            background: {t['card']};
            border: 1px solid {t['border']};
            border-radius: 14px;
            padding: 8px 12px;
            margin-bottom: 10px;
        }}
        .stButton>button {{
            background: {t['accent']} !important;
            border-radius: 999px !important;
            color: white !important;
            font-weight: 600 !important;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# ==========================================================
# ğŸŒ™ / â˜€ï¸ Tema SeÃ§ici
# ==========================================================
col_t1, col_t2 = st.columns([10,1])
with col_t2:
    dark = st.toggle("ğŸŒ™ / â˜€ï¸", value=True)

THEME = get_theme(dark)
apply_theme_css(THEME)

# ==========================================================
# ğŸ“Œ Global Session Vars
# ==========================================================
if "mode" not in st.session_state:
    st.session_state.mode = "ğŸ“¸ StÃ¼dyo Modu"

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "uploaded_chat_image" not in st.session_state:
    st.session_state.uploaded_chat_image = None

if "studio_result" not in st.session_state:
    st.session_state.studio_result = None

# END OF A1
# ==========================================================
# A2 â€” API CLIENTS â€¢ GEMINI + GPT â€¢ UTILITY FONKSÄ°YONLARI
# ==========================================================

# ---------------------------
# ğŸ”¥ Gemini Client (Google AI)
# ---------------------------
import google.generativeai as genai

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    genai.configure(api_key="")

def gemini_text(prompt: str):
    """Gemini 1.5 Pro ile metin Ã¼retimi"""
    try:
        model = genai.GenerativeModel(GEMINI_TEXT_MODEL)
        resp = model.generate_content(prompt)
        return resp.text
    except Exception as e:
        print("Gemini text error:", e)
        return "Gemini ÅŸu anda yanÄ±t veremiyor."

def gemini_vision(prompt: str, image_bytes: bytes):
    """Gemini Vision ile gÃ¶rsel analizi"""
    try:
        img = {"mime_type": "image/png", "data": image_bytes}
        model = genai.GenerativeModel(GEMINI_VISION_MODEL)
        resp = model.generate_content([prompt, img])
        return resp.text
    except Exception as e:
        print("Gemini vision error:", e)
        return "GÃ¶rsel analizinde bir hata oluÅŸtu."

def gemini_generate_image(prompt: str):
    """Gemini Image Flash ile gÃ¶rsel oluÅŸturma"""
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        img = model.generate_image(prompt=prompt, size="1024x1024")
        return img._image  # bytes
    except Exception as e:
        print("Gemini image error:", e)
        return None

# ---------------------------
# ğŸ¤– GPT-4o Client
# ---------------------------
from openai import OpenAI
GPT = OpenAI(api_key=OPENAI_API_KEY)

def gpt_chat(messages: list[dict], model: str = GPT_MODEL):
    """GPT-4o tabanlÄ± sohbet motoru"""
    try:
        res = GPT.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.25,
            max_tokens=1500,
        )
        return res.choices[0].message.content
    except Exception as e:
        print("GPT error:", e)
        return "Åu anda GPT ile baÄŸlantÄ± saÄŸlanamÄ±yor."

# ---------------------------
# âš¡ MODEL ROUTER
# ---------------------------
def model_router(mode: str):
    """
    Genel Chat = Gemini
    E-ticaret = GPT-4o
    DanÄ±ÅŸmanlÄ±k = GPT-4o
    """
    if mode == "general":
        return "gemini"
    if mode == "ecom":
        return "gpt"
    if mode == "consult":
        return "gpt"
    return "gemini"

# ==========================================================
# ğŸ“… ZAMAN FONKSÄ°YONLARI
# ==========================================================
def get_tr_time():
    try:
        r = requests.get("http://worldtimeapi.org/api/timezone/Europe/Istanbul")
        dt = r.json()["datetime"]
        return datetime.fromisoformat(dt)
    except:
        return datetime.now(ZoneInfo("Europe/Istanbul"))

def time_answer():
    now = get_tr_time()
    return f"BugÃ¼nÃ¼n tarihi: {now.strftime('%d.%m.%Y')}, Saat: {now.strftime('%H:%M')}"

# ==========================================================
# ğŸŒ¦ HAVA DURUMU SERVÄ°SÄ°
# ==========================================================
def get_coords(city: str):
    try:
        url = (
            f"http://api.openweathermap.org/geo/1.0/direct?"
            f"q={city},TR&limit=1&appid={WEATHER_API_KEY}"
        )
        r = requests.get(url)
        data = r.json()
        if not data: return None
        return data[0]["lat"], data[0]["lon"]
    except:
        return None

def get_weather(city: str):
    coords = get_coords(city)
    if not coords:
        return f"{city} iÃ§in konum bulunamadÄ±."

    lat, lon = coords
    try:
        url = (
            f"https://api.openweathermap.org/data/2.5/weather?"
            f"lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric&lang=tr"
        )
        r = requests.get(url)
        d = r.json()

        desc = d["weather"][0]["description"].capitalize()
        temp = d["main"]["temp"]
        hum = d["main"]["humidity"]
        wind = d["wind"]["speed"]

        return (
            f"ğŸ“ **{city.title()}**\n"
            f"ğŸŒ¡ï¸ SÄ±caklÄ±k: **{temp:.1f}Â°C**\n"
            f"â˜ï¸ Hava: **{desc}**\n"
            f"ğŸ’§ Nem: **%{hum}**\n"
            f"ğŸƒ RÃ¼zgar: **{wind} m/s**"
        )
    except:
        return "Hava durumu alÄ±namadÄ±."

# ==========================================================
# ğŸ›¡ GÃœVENLÄ°K FÄ°LTRESÄ°
# ==========================================================
BAD_WORDS = [
    r"(?i)orospu", r"(?i)siktir", r"(?i)amk",
    r"(?i)tecavÃ¼z", r"(?i)intihar", r"(?i)bomba yap",
]

def moderate_text(msg: str) -> str | None:
    for pat in BAD_WORDS:
        if re.search(pat, msg):
            return "Bu isteÄŸe gÃ¼venlik nedeniyle yanÄ±t veremiyorum. ğŸ™"
    return None
# ==========================================================
# A3 â€” STÃœDYO MODU â€¢ GÃ–RSEL Ä°ÅLEME (GEMINI + LOCAL)
# ==========================================================

# ---------------------------------------
# ğŸ§¼ 1) LOKAL ARKA PLAN KALDIRMA (HQ)
# ---------------------------------------
def remove_bg_local(image: Image.Image) -> Image.Image:
    """
    Lokal yÃ¼ksek kalite maskeleme.
    Gemini Vision ÅŸu anda 'edit image' desteklemediÄŸi iÃ§in
    keskin ve gÃ¼venilir bir yÃ¶ntem kullanÄ±yoruz.
    """
    if image.mode != "RGBA":
        image = image.convert("RGBA")

    # Alfa maskesi Ã¼ret
    gray = image.convert("L")
    mask = gray.point(lambda p: 255 if p > 240 else 0)

    result = Image.new("RGBA", image.size)
    result.paste(image, (0, 0), mask)
    return result


# ---------------------------------------
# ğŸ› 2) ÃœRÃœNÃœ KARE TUVALE YERLEÅTÄ°RME
# ---------------------------------------
def center_on_canvas(img: Image.Image, size=1024) -> Image.Image:
    canvas = Image.new("RGBA", (size, size), (0, 0, 0, 0))
    img = img.copy()
    img.thumbnail((size * 0.85, size * 0.85), Image.Resampling.LANCZOS)

    x = (size - img.width) // 2
    y = (size - img.height) // 2
    canvas.paste(img, (x, y), img)
    return canvas


# ---------------------------------------
# ğŸŒ“ 3) PROFESYONEL TEMAS GÃ–LGESÄ°
# ---------------------------------------
def make_contact_shadow(alpha: Image.Image, intensity=140):
    a = alpha.convert("L")
    box = a.getbbox()
    if not box:
        return Image.new("L", a.size, 0)

    w = box[2] - box[0]
    h = int((box[3] - box[1]) * 0.22)

    shadow = Image.new("L", (w, h), 0)
    draw = ImageDraw.Draw(shadow)
    draw.ellipse([0, 0, w, h], fill=intensity)
    shadow = shadow.filter(ImageFilter.GaussianBlur(radius=h // 2))

    mask = Image.new("L", a.size, 0)
    mask.paste(shadow, (box[0], box[3] - h // 2))
    return mask


# ---------------------------------------
# ğŸŒ« 4) HAFÄ°F STÃœDYO YANSIMA
# ---------------------------------------
def make_reflection(img: Image.Image, fade=220):
    a = img.split()[3]
    box = a.getbbox()
    if not box:
        return Image.new("RGBA", img.size, (0, 0, 0, 0))

    crop = img.crop(box)
    flip = ImageOps.flip(crop)

    grad = Image.linear_gradient("L").resize((1, flip.height))
    grad = grad.point(lambda p: int(p * (fade / 255)))
    grad = grad.resize(flip.size)

    flip.putalpha(grad)

    out = Image.new("RGBA", img.size, (0, 0, 0, 0))
    out.paste(flip, (box[0], box[3] + 4), flip)
    return out


# ---------------------------------------
# ğŸ¨ 5) TEMA KOMPOZÄ°T MOTORU
# ---------------------------------------
def compose_scene(cut: Image.Image, bg_color: str, reflection=True, shadow=True):
    side = 1024
    obj = center_on_canvas(cut, side)
    alpha = obj.split()[3]

    # Arka plan
    bg_colors = {
        "white": (255, 255, 255, 255),
        "black": (0, 0, 0, 255),
        "beige": (245, 240, 225, 255),
    }

    bg = Image.new("RGBA", (side, side), bg_colors.get(bg_color, (255, 255, 255, 255)))
    out = Image.new("RGBA", (side, side), (0, 0, 0, 0))
    out.alpha_composite(bg)

    # GÃ¶lge
    if shadow:
        sh_mask = make_contact_shadow(alpha)
        sh = Image.new("RGBA", (side, side), (0, 0, 0, 0))
        sh.putalpha(sh_mask)
        out.alpha_composite(sh)

    # YansÄ±ma
    if reflection:
        ref = make_reflection(obj)
        out.alpha_composite(ref)

    # ÃœrÃ¼n
    out.alpha_composite(obj)
    return out


# ---------------------------------------
# âœ¨ 6) GEMINI SAHNE OLUÅTURMA (AI)
# ---------------------------------------
def gemini_edit_scene(prompt: str, product_image: bytes):
    """
    StÃ¼dyo modunda serbest sahne oluÅŸturma:
    - Gemini Flash Image kullanÄ±r.
    - ÃœrÃ¼n korunur, yalnÄ±zca arka plan AI tarafÄ±ndan yeniden Ã§izilir.
    """
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")

        img_dict = {
            "mime_type": "image/png",
            "data": product_image,
        }

        full_prompt = (
            "You are a professional product photographer. "
            "Replace only the background with a clean, elegant, commercial-grade scene. "
            "Do NOT modify the product shape, color or geometry. "
            f"Scene prompt: {prompt}"
        )

        result = model.generate_image(
            prompt=full_prompt,
            image=img_dict,
            size="1024x1024",
        )

        return result._image  # raw PNG bytes
    except Exception as e:
        print("Gemini Edit Scene Error:", e)
        return None


# ---------------------------------------
# ğŸ— 7) TEMALAR
# ---------------------------------------
PRESETS = {
    "ğŸ§¹ Åeffaf Arka Plan": "transparent",
    "â¬œ Beyaz Arka Plan": "white",
    "â¬› Siyah Arka Plan": "black",
    "ğŸ¦ Bej Arka Plan": "beige",
    "âœ¨ Profesyonel StÃ¼dyo": "pro",
}

def apply_preset(img: Image.Image, preset_name: str):
    """HazÄ±r temayÄ± uygular."""
    cut = remove_bg_local(img)

    if preset_name == "transparent":
        return cut

    if preset_name == "white":
        return compose_scene(cut, "white", reflection=False)

    if preset_name == "black":
        return compose_scene(cut, "black", reflection=False)

    if preset_name == "beige":
        return compose_scene(cut, "beige", reflection=False)

    if preset_name == "pro":
        return compose_scene(cut, "white", reflection=True)

    return cut
# ==========================================================
# A4 â€” GENEL CHAT MOTORU (GEMINI 1.5 PRO)
# ==========================================================

# âœ” Metin destekli
# âœ” GÃ¶rsel destekli
# âœ” GÃ¶rsel oluÅŸturma yetenekleri
# âœ” GPTâ€™den tamamen baÄŸÄ±msÄ±z Ã§alÄ±ÅŸÄ±r (sadece Genel Chat iÃ§in)

def gemini_general_chat(user_message: str, user_image: bytes | None):
    """
    Genel Chat Modu (ğŸ’¬) iÃ§in Gemini 1.5 Pro tabanlÄ± yanÄ±t Ã¼retici.
    - Tek mesajlÄ±k deÄŸil, Ã§oklu geÃ§miÅŸle birlikte Ã§alÄ±ÅŸabilir.
    - GÃ¶rsel analizi otomatik algÄ±lar.
    """

    try:
        history = []
        # Sohbet geÃ§miÅŸini Gemini formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
        for msg in st.session_state.chat_history[-20:]:
            if msg["role"] == "user":
                history.append({
                    "role": "user",
                    "parts": [msg["content"]]
                })
            else:
                history.append({
                    "role": "model",
                    "parts": [msg["content"]]
                })

        # KullanÄ±cÄ±nÄ±n yeni mesajÄ± & gÃ¶rseli
        user_parts = [{"text": user_message}]

        if user_image:
            user_parts.append({
                "inline_data": {
                    "mime_type": "image/png",
                    "data": base64.b64encode(user_image).decode("utf-8")
                }
            })

        # Gemini sohbet modeli
        model = genai.GenerativeModel("gemini-1.5-pro")

        chat_turn = {
            "role": "user",
            "parts": user_parts
        }

        full_messages = history + [chat_turn]

        response = model.generate_content(full_messages)

        if hasattr(response, "text"):
            return response.text
        return "Bir yanÄ±t Ã¼retemedim."
    except Exception as e:
        print("Gemini Chat Error:", e)
        return "ÃœzgÃ¼nÃ¼m, ÅŸu anda bir sorun oluÅŸtu. Daha sonra tekrar dene."


# ==========================================================
# A4 â€” GÃ–RSEL OLUÅTURMA MOTORU (Gemini Flash Image)
# ==========================================================

def gemini_generate_image(prompt: str, size: str = "1024x1024"):
    """
    Gemini Flash ile yÃ¼ksek kaliteli gÃ¶rsel oluÅŸturma.
    Genel Chat iÃ§inde:
        â¤ â€œBir logo Ã¼retâ€
        â¤ â€œBu Ã¼rÃ¼nÃ¼ plajda gÃ¶sterâ€
        â¤ â€œMinimalist arka plan resmi Ã§izâ€
    gibi istekleri karÅŸÄ±lar.
    """
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")

        result = model.generate_image(
            prompt=prompt,
            size=size,
        )

        return result._image  # PNG raw bytes
    except Exception as e:
        print("Gemini Generate Image Error:", e)
        return None


# ==========================================================
# A4 â€” GENEL CHATTE OTOMATÄ°K ALGILAMA
# ==========================================================

def handle_general_chat(user_message: str):
    """
    Genel chat iÅŸleyici:
    - KullanÄ±cÄ±nÄ±n gÃ¶rsel oluÅŸturmak istediÄŸini otomatik algÄ±lar.
    - Metin isteklerini Gemini 1.5 Proâ€™ya yÃ¶nlendirir.
    """

    # KullanÄ±cÄ± gÃ¶rsel oluÅŸturmak istiyor mu?
    GEN_TRIGGER = [
        "gÃ¶rsel oluÅŸtur",
        "resim oluÅŸtur",
        "image create",
        "bir gÃ¶rsel Ã§iz",
        "bana bir tasarÄ±m yap",
        "foto Ã¼ret",
        "generate image"
    ]

    # 1) EÄŸer gÃ¶rsel Ã¼retim tetikleniyorsa â†’ Gemini Flash Ã§alÄ±ÅŸÄ±r
    if any(t in user_message.lower() for t in GEN_TRIGGER):
        with st.chat_message("assistant"):
            st.write("ğŸ¨ GÃ¶rsel oluÅŸturuluyor...")

        img_bytes = gemini_generate_image(user_message)

        if img_bytes:
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": "(GÃ¶rsel oluÅŸturuldu)"
            })

            st.image(img_bytes, caption="Gemini 1.5 Flash tarafÄ±ndan Ã¼retildi", width=350)
            return

        st.write("GÃ¶rsel oluÅŸturma baÅŸarÄ±sÄ±z oldu, lÃ¼tfen tekrar dene.")
        return

    # 2) Normal metin/gÃ¶rsel analiz sohbeti
    output = gemini_general_chat(
        user_message,
        st.session_state.chat_image
    )

    with st.chat_message("assistant"):
        st.write(output)

    st.session_state.chat_history.append({
        "role": "assistant",
        "content": output
    })
# ==========================================================
# A5 â€” GPT TABANLI E-TÄ°CARET VE DANIÅMANLIK MOTORU
# ==========================================================

def gpt_assistant(profile: Literal["ecom", "consult"]):
    """
    GPT-4o tabanlÄ± E-Ticaret ve DanÄ±ÅŸmanlÄ±k asistanÄ±.
    Bu motor Genel Chat motorundan tamamen ayrÄ± Ã§alÄ±ÅŸÄ±r.
    """

    # ----- Sistem mesajÄ± oluÅŸtur -----
    system_message = build_system_talimati(profile)

    # ----- Sohbet geÃ§miÅŸi -----
    history = []
    for msg in st.session_state.chat_history[-30:]:
        history.append({
            "role": "user" if msg["role"] == "user" else "assistant",
            "content": msg["content"]
        })

    # ----- GPT isteÄŸi -----
    try:
        client = OpenAI(api_key=SABIT_API_KEY)

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_message},
                *history
            ],
            temperature=0.25,
            max_tokens=1400,
        )

        return response.choices[0].message.content

    except Exception as e:
        print("GPT-4o error:", e)

        # ----- Fallback: GPT-4o-mini -----
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_message},
                    *history
                ],
                temperature=0.25,
                max_tokens=1200,
            )
            return response.choices[0].message.content

        except Exception as err:
            print("GPT fallback error:", err)
            return "Åu anda bir problem oluÅŸtu. LÃ¼tfen tekrar dener misin?"



# ==========================================================
# A5 â€” GPT ASÄ°STANI HANDLE (UI BaÄŸlayÄ±cÄ±)
# ==========================================================

def handle_gpt_assistant(profile: Literal["ecom", "consult"], user_message: str):
    """
    UI â†’ GPT AsistanÄ± baÄŸlayÄ±cÄ±sÄ±.
    Bu fonksiyon:
        - Upload'Ä± ekler
        - GÃ¼venlik filtresini uygular
        - Sistem intercept'leri yÃ¼rÃ¼tÃ¼r
        - GPT yanÄ±tÄ±nÄ± UI'da gÃ¶sterir
    """

    # 1ï¸âƒ£ GÃ¼venlik filtresi
    mod = moderate_content(user_message)
    if mod:
        with st.chat_message("assistant"):
            st.write(mod)
        st.session_state.chat_history.append({"role": "assistant", "content": mod})
        return

    # 2ï¸âƒ£ Sistem intercept (zaman, kimlik, hava durumu)
    util = custom_utility_interceptor(user_message)
    ident = custom_identity_interceptor(user_message)

    if ident or util:
        result = ident or util
        with st.chat_message("assistant"):
            st.write(result)
        st.session_state.chat_history.append({"role": "assistant", "content": result})
        return

    # 3ï¸âƒ£ Normal GPT Asistan Ä°ÅŸlemi
    with st.chat_message("assistant"):
        with st.spinner("Qelyon AI dÃ¼ÅŸÃ¼nÃ¼yor..."):
            answer = gpt_assistant(profile)
            st.write(answer)

    st.session_state.chat_history.append({"role": "assistant", "content": answer})
# ==========================================================
# A6 â€” ÃœÃ‡ MOD ARAYÃœZÃœ VE MOTOR SEÃ‡Ä°MÄ° (Gemini + GPT)
# ==========================================================

def render_main_modes():

    st.markdown("### ğŸ¤– Mod SeÃ§imi")

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ’¬ Genel Chat (Gemini)", use_container_width=True,
                     type="primary" if st.session_state.app_mode == "GENERAL_CHAT" else "secondary"):
            st.session_state.app_mode = "GENERAL_CHAT"
            st.session_state.chat_history = [
                {"role": "assistant", "content": "Merhaba! Gemini tabanlÄ± Genel Chat'e hoÅŸ geldin. NasÄ±l yardÄ±mcÄ± olabilirim?"}
            ]
            st.session_state.chat_image = None
            st.rerun()

    with col2:
        if st.button("ğŸ›’ E-Ticaret AsistanÄ± (GPT-4o)", use_container_width=True,
                     type="primary" if st.session_state.app_mode == "ECOM" else "secondary"):
            st.session_state.app_mode = "ECOM"
            st.session_state.chat_history = [
                {"role": "assistant", "content": "E-Ticaret AsistanÄ± aktif! ÃœrÃ¼n bilgilerini yazmaya hazÄ±rÄ±m."}
            ]
            st.session_state.chat_image = None
            st.rerun()

    with col3:
        if st.button("ğŸ’¼ DanÄ±ÅŸmanlÄ±k AsistanÄ± (GPT-4o)", use_container_width=True,
                     type="primary" if st.session_state.app_mode == "CONSULT" else "secondary"):
            st.session_state.app_mode = "CONSULT"
            st.session_state.chat_history = [
                {"role": "assistant", "content": "DanÄ±ÅŸmanlÄ±k AsistanÄ± aktif! Ä°ÅŸini bana anlat, birlikte geliÅŸtirelim."}
            ]
            st.session_state.chat_image = None
            st.rerun()

    st.divider()



# ==========================================================
# A6 â€” GENEL CHAT (GEMINI MOTORU)
# ==========================================================

def general_chat_ui():
    st.markdown("### ğŸ’¬ Gemini â€” Genel Chat")
    st.caption("Metin, gÃ¶rsel analizi ve gÃ¶rsel oluÅŸturma iÃ§in hazÄ±r!")

    # Mesaj geÃ§miÅŸi
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Upload bÃ¶lÃ¼mÃ¼
    upload = st.file_uploader(
        "GÃ¶rsel / PDF / Dosya ekle",
        type=["png", "jpg", "jpeg", "webp", "pdf"],
        key="general_upload"
    )

    if upload:
        st.session_state.chat_image = upload.read()
        st.success("Dosya yÃ¼klendi!")

    prompt = st.chat_input("Bir mesaj yaz...")

    if prompt:
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        # ---- Gemini Ã§aÄŸrÄ±sÄ± ----
        from google import generativeai as gen

        gen.configure(api_key=st.secrets["GEMINI_API_KEY"])

        model = gen.GenerativeModel("gemini-1.5-pro")

        parts = [prompt]

        # GÃ¶rsel ekli ise vision input ekle
        if st.session_state.chat_image:
            import mimetypes
            mime = mimetypes.guess_type("x")[0] or "image/png"
            parts.append({
                "mime_type": mime,
                "data": st.session_state.chat_image
            })

        with st.chat_message("assistant"):
            with st.spinner("Gemini dÃ¼ÅŸÃ¼nÃ¼yor..."):
                response = model.generate_content(parts)
                answer = response.text
                st.write(answer)

        st.session_state.chat_history.append({"role": "assistant", "content": answer})



# ==========================================================
# A6 â€” ROUTER (Hangi mod aÃ§Ä±lacak?)
# ==========================================================

def run_assistant_router():

    # 1ï¸âƒ£ Mod butonlarÄ±nÄ± Ã§iz
    render_main_modes()

    # 2ï¸âƒ£ Modâ€™a gÃ¶re motor Ã§alÄ±ÅŸtÄ±r
    if st.session_state.app_mode == "GENERAL_CHAT":
        general_chat_ui()

    elif st.session_state.app_mode == "ECOM":
        handle_gpt_assistant("ecom", st.chat_input("Mesaj yazÄ±n..."))

    elif st.session_state.app_mode == "CONSULT":
        handle_gpt_assistant("consult", st.chat_input("Mesaj yazÄ±n..."))
# ============================
# QELYON AI STÃœDYO â€” FINAL v7
# Hybrid Multi-Model System
# Gemini Vision + GPT-4o
# ============================

# =======================================================
# CONFIG & SECRETS
# =======================================================

# ---- API Keys ----
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", None)
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", None)
WEATHER_API_KEY = st.secrets.get("WEATHER_API_KEY", None)

if not GEMINI_API_KEY:
    st.error("âŒ Gemini API anahtarÄ± bulunamadÄ±. 'secrets.toml' iÃ§ine eklemelisiniz.")
if not OPENAI_API_KEY:
    st.error("âŒ OpenAI API anahtarÄ± bulunamadÄ±. GPT tabanlÄ± modlar Ã§alÄ±ÅŸmayacaktÄ±r.")

# ---- Google Gemini Setup ----
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ---- OpenAI Setup ----
openai_client = None
if OPENAI_API_KEY:
    openai_client = OpenAI(api_key=OPENAI_API_KEY)

# ---- Model Names ----
GEMINI_FLASH = "gemini-1.5-flash"
GEMINI_PRO   = "gemini-1.5-pro"
OPENAI_GPT   = st.secrets.get("OPENAI_MODEL", "gpt-4o")


# =======================================================
# PAGE CONFIG
# =======================================================

st.set_page_config(
    page_title="Qelyon AI StÃ¼dyo",
    page_icon="favicn.png",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =======================================================
# THEME COLORS
# =======================================================

def get_theme(is_dark: bool):
    return {
        "bg": "#050509" if is_dark else "#F7F8FE",
        "text": "#FFFFFF" if is_dark else "#0A0A0C",
        "subtext": "#A0AEC0" if is_dark else "#555",
        "card": "rgba(255,255,255,0.04)" if is_dark else "rgba(255,255,255,0.70)",
        "border": "rgba(255,255,255,0.1)" if is_dark else "rgba(0,0,0,0.1)",
        "accent": "#6C47FF",
        "accent_hover": "#5830E0",
        "input": "rgba(255,255,255,0.08)" if is_dark else "#FFFFFF",
    }

def inject_css(theme):
    st.markdown(f"""
<style>

body, .stApp {{
    background: {theme['bg']} !important;
    color: {theme['text']};
    font-family: 'Inter', sans-serif;
}}

.stTextInput input, textarea {{
    background: {theme['input']} !important;
    color: {theme['text']} !important;
    border-radius: 12px !important;
    border: 1px solid {theme['border']} !important;
}}

[data-testid="stChatInput"] textarea {{
    background: {theme['input']} !important;
    color: {theme['text']} !important;
    border-radius: 999px !important;
}}

.stButton>button {{
    background-color: {theme['accent']} !important;
    border-radius: 999px !important;
    color: white;
    border: none;
    font-weight: 600;
    padding: 8px 18px;
}}

.stButton>button:hover {{
    background-color: {theme['accent_hover']} !important;
}}

.image-card {{
    background: {theme['card']};
    backdrop-filter: blur(18px);
    border-radius: 16px;
    padding: 14px;
    border: 1px solid {theme['border']};
}}

</style>
    """, unsafe_allow_html=True)


# ==============================================================  
# Voice-to-Text â€” Web Speech API
# ==============================================================

def inject_voice_js():
    st.markdown("""
<script>
(function() {
  const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
  if (!SpeechRecognition) return;

  function mount() {
    const root = window.parent.document.querySelector('[data-testid="stChatInput"]');
    if (!root) return;
    if (root.querySelector('#qelyon-mic')) return;

    const textarea = root.querySelector('textarea');
    if (!textarea) return;

    const btn = document.createElement('button');
    btn.id = 'qelyon-mic';
    btn.innerHTML = 'ğŸ¤';
    btn.style.marginLeft = '8px';
    btn.style.background = '#6C47FF';
    btn.style.color = 'white';
    btn.style.borderRadius = '999px';
    btn.style.border = 'none';
    btn.style.padding = '5px 10px';
    btn.style.cursor = 'pointer';

    const rec = new SpeechRecognition();
    rec.lang = 'tr-TR';
    rec.onresult = (e) => {
        textarea.value = textarea.value + " " + e.results[0][0].transcript;
        textarea.dispatchEvent(new Event('input', { bubbles: true }));
    };

    btn.onclick = () => rec.start();
    root.appendChild(btn);
  }

  setInterval(mount, 1200);
})();
</script>
    """, unsafe_allow_html=True)
# ============================================================
# A7-2 â€” GÃ–RSEL Ä°ÅLEME MOTORU (GEMINI 1.5 VISION)
# ============================================================

# PDF dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in
from pdf2image import convert_from_bytes


# -----------------------------
# PDF â†’ PNG dÃ¶nÃ¼ÅŸÃ¼mÃ¼
# -----------------------------
def pdf_to_png(pdf_bytes: bytes) -> Image.Image:
    """
    KullanÄ±cÄ± PDF yÃ¼klediÄŸinde ilk sayfayÄ± gÃ¶rÃ¼ntÃ¼ye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    (Gemini PDF destekler ama gÃ¶rÃ¼ntÃ¼ iÅŸlemede PNG daha stabil.)
    """
    try:
        pages = convert_from_bytes(pdf_bytes, dpi=200)
        return pages[0].convert("RGBA")
    except Exception as e:
        print("PDF dÃ¶nÃ¼ÅŸtÃ¼rme hatasÄ±:", e)
        return None


# -----------------------------
# Gemini Vision model seÃ§ici
# -----------------------------
def get_gemini_model(vision: bool = True):
    if vision:
        return genai.GenerativeModel(GEMINI_FLASH)  # hÄ±zlÄ± + gÃ¶rsel desteÄŸi
    return genai.GenerativeModel(GEMINI_PRO)


# -----------------------------
# GÃ¶rseli daha kaliteli iÅŸlemek iÃ§in
# 1024x1024 kare tuvale yerleÅŸtir
# -----------------------------
def prepare_image_square(image: Image.Image, side: int = 1024) -> Image.Image:
    img = image.copy()
    img.thumbnail((side - 100, side - 100))

    canvas = Image.new("RGBA", (side, side), (0, 0, 0, 0))
    x = (side - img.width) // 2
    y = (side - img.height) // 2
    canvas.paste(img, (x, y), img if img.mode == "RGBA" else None)
    return canvas


# -----------------------------
# Gemini Vision â€” Arka Plan KaldÄ±rma
# -----------------------------
def gemini_remove_background(image: Image.Image) -> Image.Image:
    """
    Gemini Vision ile geliÅŸmiÅŸ HQ arka plan kaldÄ±rma.
    Ä°nce zincir, saÃ§, Ã¶rgÃ¼ dokularÄ±nÄ± yÃ¼ksek doÄŸrulukla korur.
    """
    try:
        # Gemini Vision'a gÃ¶nderilecek veri
        img_bytes = io.BytesIO()
        image.save(img_bytes, format="PNG")
        img_bytes = img_bytes.getvalue()

        model = get_gemini_model(vision=True)

        response = model.generate_content(
            [
                {
                    "mime_type": "image/png",
                    "data": img_bytes
                },
                "Remove the entire background. Preserve object edges, metallic reflections, chains, fibers, and small details. Output alpha-transparent PNG."
            ],
            generation_config={
                "temperature": 0.1
            }
        )

        # Ã‡Ä±ktÄ± gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ decode et
        img_data = response._result.candidates[0].content.parts[0].raw_bytes
        return Image.open(io.BytesIO(img_data)).convert("RGBA")

    except Exception as e:
        print("Gemini remove_bg hata:", e)
        return image


# -----------------------------
# Gemini Vision â€” Image Edit / Scene Generation
# -----------------------------
def gemini_edit_scene(image: Image.Image, prompt: str) -> Optional[bytes]:
    """
    KullanÄ±cÄ±nÄ±n serbest yazÄ±m sahne aÃ§Ä±klamasÄ±na gÃ¶re AI ile gÃ¶rsel oluÅŸturur.
    ÃœrÃ¼n deÄŸiÅŸtirilmez, sadece sahne tasarlanÄ±r.
    """
    try:
        model = get_gemini_model(vision=True)

        img_bytes = io.BytesIO()
        image.save(img_bytes, format="PNG")
        img_bytes = img_bytes.getvalue()

        response = model.generate_content(
            [
                {
                    "mime_type": "image/png",
                    "data": img_bytes
                },
                (
                    "Preserve the original product EXACTLY. "
                    "Do NOT modify shape, color, brand, or geometry. "
                    "Replace the background based on the following scene instructions: "
                    + prompt
                )
            ],
            generation_config={
                "temperature": 0.15,
                "max_output_tokens": 2048,
            }
        )

        img_data = response._result.candidates[0].content.parts[0].raw_bytes
        return img_data

    except Exception as e:
        print("Gemini edit hata:", e)
        return None


# -----------------------------
# KullanÄ±cÄ± gÃ¶rselini normalize et
# -----------------------------
def load_user_image(uploaded_file):
    """
    PDF â†’ PNG
    JPG/PNG â†’ RGBA
    Orientation fix
    """
    try:
        if uploaded_file.type == "application/pdf":
            return pdf_to_png(uploaded_file.read())

        img = Image.open(uploaded_file)
        img = ImageOps.exif_transpose(img)
        return img.convert("RGBA")

    except Exception as e:
        print("GÃ¶rsel yÃ¼kleme hatasÄ±:", e)
        return None
# ============================================================
# A7-3 â€” GENEL CHAT MOTORU (GEMINI PRO + GEMINI VISION)
# ============================================================

# -------------------------------------------
# Gemini ile GÃ¶rsel Analizi
# -------------------------------------------
def gemini_analyze_image(img_bytes: bytes, prompt: str = "") -> str:
    """
    Genel chat iÃ§inde gÃ¶rsel varsa analiz etmek iÃ§in.
    """
    try:
        model = get_gemini_model(vision=True)

        response = model.generate_content(
            [
                {"mime_type": "image/png", "data": img_bytes},
                (
                    "Analyze the uploaded image in detail. "
                    "Describe its content, objects, colors, textures, style, and scene. "
                    + prompt
                )
            ],
            generation_config={"temperature": 0.2}
        )

        return response.text

    except Exception as e:
        print("Gemini gÃ¶rsel analiz hatasÄ±:", e)
        return "GÃ¶rseli iÅŸlerken bir hata oluÅŸtu."


# -------------------------------------------
# Gemini ile GÃ¶rsel OluÅŸturma (Text â†’ Image)
# -------------------------------------------
def gemini_generate_image(prompt: str) -> Optional[bytes]:
    """
    Genel chat iÃ§inde: â€œBu promptla gÃ¶rsel Ã¼retâ€ gibi isteklerde.
    """
    try:
        model = get_gemini_model(vision=False)

        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": 0.3,
                "max_output_tokens": 2048
            }
        )

        img_data = response._result.candidates[0].content.parts[0].raw_bytes
        return img_data

    except Exception as e:
        print("Gemini gÃ¶rsel oluÅŸturma hatasÄ±:", e)
        return None


# -------------------------------------------
# Kimlik YanÄ±tÄ± (Qelyon AI)
# -------------------------------------------
def chat_identity_intercept(message: str) -> Optional[str]:
    msg = message.lower().strip()

    triggers = [
        "kimsin", "sen kimsin", "kim geliÅŸtirdi", "seni kim yaptÄ±", "who are you",
        "who created you", "kim yarattÄ±"
    ]

    if any(t in msg for t in triggers):
        return (
            "Ben **Qelyon AI**.\n"
            "Profesyonel Ã¼retkenlik, gÃ¶rsel iÅŸleme ve danÄ±ÅŸmanlÄ±k Ã§Ã¶zÃ¼mleri sunan geliÅŸmiÅŸ bir yapay zekayÄ±m. "
            "GÃ¶rselleri iÅŸler, iÃ§erik Ã¼retir ve iÅŸ stratejisi geliÅŸtirmen iÃ§in destek saÄŸlarÄ±m. ğŸš€"
        )
    return None


# -------------------------------------------
# Saat / Tarih / Hava Durumu intercept
# -------------------------------------------
def chat_utility_intercept(message: str) -> Optional[str]:
    text = message.lower()

    # Saat & tarih (tarihÃ§esi olmasÄ±n)
    if "saat" in text or "tarih" in text:
        if "tarihi" not in text and "tarihÃ§esi" not in text:
            return get_time_answer()

    # 7 gÃ¼nlÃ¼k
    if "7 gÃ¼nlÃ¼k hava" in text or "haftalÄ±k hava" in text:
        city = extract_city_from_message(message)
        return get_weather_forecast_answer(city)

    # tek gÃ¼n hava durumu
    if "hava" in text or "hava durumu" in text:
        city = extract_city_from_message(message)
        return get_weather_answer(city)

    return None


# -------------------------------------------
# GÃ¼venlik filtresi
# -------------------------------------------
def chat_moderate(message: str) -> Optional[str]:
    return moderate_content(message)


# -------------------------------------------
# Genel Chat â€” Gemini Pro Cevap Motoru
# -------------------------------------------
def general_chat_gemini(message: str, image_bytes: Optional[bytes] = None) -> str:
    """
    Genel Chat â†’ Gemini 1.5 Pro kullanÄ±r.
    GÃ¶rsel eklendi ise otomatik analiz eder.
    """
    # GÃ¼venlik
    sec = chat_moderate(message)
    if sec:
        return sec

    # Kimlik & saat & hava intercept
    ident = chat_identity_intercept(message)
    if ident:
        return ident

    util = chat_utility_intercept(message)
    if util:
        return util

    # GÃ¶rsel yÃ¼klendiyse analiz
    if image_bytes is not None:
        return gemini_analyze_image(
            image_bytes,
            prompt=(
                "GÃ¶rseli analiz et. EÄŸer kullanÄ±cÄ± e-ticaret aÃ§Ä±klamasÄ± isterse "
                "Ã¼rÃ¼nÃ¼n malzemesi, renk tonu, kullanÄ±m alanÄ±, kategori ve stilini belirt."
            )
        )

    # Normal metin â†’ Gemini Pro
    try:
        model = get_gemini_model(vision=False)

        response = model.generate_content(
            message,
            generation_config={"temperature": 0.25, "max_output_tokens": 2000},
        )
        return response.text

    except Exception as e:
        print("Genel chat API hatasÄ±:", e)
        return "Åu an Gemini ile baÄŸlantÄ± kuramÄ±yorum. BirkaÃ§ saniye sonra tekrar deneyebilirsin."


# -------------------------------------------
# Genel Chat GÃ¶rsel Ãœretim Komutu AlgÄ±layÄ±cÄ±
# -------------------------------------------
def detect_generate_image_command(message: str) -> Optional[str]:
    """
    KullanÄ±cÄ±: 'bana ÅŸÃ¶yle bir gÃ¶rsel Ã¼ret' dediÄŸinde tetiklenir.
    """
    triggers = [
        "gÃ¶rsel Ã¼ret",
        "resim oluÅŸtur",
        "image generate",
        "fotoÄŸraf oluÅŸtur",
        "bir gÃ¶rsel yap"
    ]

    msg = message.lower()
    if any(t in msg for t in triggers):
        return message  # prompt olarak kullanÄ±lÄ±r

    return None
# ============================================================
# A7-4 â€” E-TÄ°CARET & DANIÅMANLIK YAPAY ZEKA MOTORU (GPT-4o)
# ============================================================

# ------------------------------------------------------------
# GPT-4o istemci oluÅŸturucu
# ------------------------------------------------------------
def get_gpt_client():
    if not SABIT_API_KEY:
        return None
    try:
        return OpenAI(api_key=SABIT_API_KEY)
    except:
        return None


# ------------------------------------------------------------
# E-Ticaret System Prompt
# ------------------------------------------------------------
def system_prompt_ecommerce():
    now = turkce_zaman_getir()
    return f"""
Sen Qelyon AI'sÄ±n.
UzmanlÄ±k alanÄ±n: e-ticaret satÄ±ÅŸ optimizasyonu, Ã¼rÃ¼n aÃ§Ä±klamalarÄ±, varyant analizi,
kampanya iÃ§erikleri ve pazaryeri SEOâ€™su.

YazÄ±m stilin:
- Profesyonel
- ÃœrÃ¼n faydasÄ±nÄ± hÄ±zlÄ± anlatan
- Madde madde net ifadeler
- Gereksiz sÃ¼sleme yok

Zorunlu format:

1) KÄ±sa giriÅŸ paragrafÄ±  
2) Ã–ne Ã§Ä±kan 5 fayda  
3) Kutu iÃ§eriÄŸi  
4) Hedef kitle  
5) KullanÄ±m Ã¶nerileri  
6) SatÄ±n almaya yÃ¶nlendiren CTA  

Ek gÃ¶revler:  
- KullanÄ±cÄ± isterse Trendyol etiketleri Ã¼ret  
- ÃœrÃ¼n baÅŸlÄ±ÄŸÄ± iÃ§in A/B test versiyonlarÄ± Ã§Ä±kar  
- ÃœrÃ¼nÃ¼n olasÄ± varyantlarÄ±nÄ± (renk/boyut/kapasite) analiz et  
- MÃ¼ÅŸteri yorumu verilirse memnuniyet & ÅŸikayet temalarÄ± Ã§Ä±kar  
- Sosyal medya reklam metni Ã¼retebilirsin  

Bu yanÄ±t {now} tarihinde oluÅŸturulmuÅŸtur.
"""


# ------------------------------------------------------------
# DanÄ±ÅŸmanlÄ±k System Prompt
# ------------------------------------------------------------
def system_prompt_consulting():
    now = turkce_zaman_getir()
    return f"""
Sen Qelyon AI'sÄ±n.
Profesyonel iÅŸ ve yÃ¶netim danÄ±ÅŸmanÄ±sÄ±n.

UzmanlÄ±k alanlarÄ±n:
- Åirket bÃ¼yÃ¼me stratejileri
- OKR & KPI geliÅŸtirme
- Pazarlama hunisi optimizasyonu
- Ä°ÅŸ modeli analizleri
- Finansal varsayÄ±m ile planlama
- Segmentasyon & mÃ¼ÅŸteri analizi

YanÄ±t stilin:
- Net, uygulanabilir
- GerektiÄŸinde maddeli aÃ§Ä±klamalar
- Belirsizlik varsa varsayÄ±m belirt
- Stratejik iÃ§gÃ¶rÃ¼ Ã¼ret

Bu yanÄ±t {now} tarihinde oluÅŸturulmuÅŸtur.
"""


# ------------------------------------------------------------
# E-Ticaret Prompt Ä°ÅŸleyici
# ------------------------------------------------------------
def ecommerce_process_prompt(user_msg: str, img_bytes: Optional[bytes]) -> str:
    client = get_gpt_client()
    if not client:
        return "GPT hizmeti ÅŸu anda kullanÄ±lamÄ±yor."

    messages = [
        {"role": "system", "content": system_prompt_ecommerce()},
    ]

    # EÄŸer gÃ¶rsel varsa GPTâ€™ye aÃ§Ä±klamada yardÄ±mcÄ± olmasÄ± iÃ§in metin ekleriz
    if img_bytes is not None:
        encoded = base64.b64encode(img_bytes).decode("utf-8")
        messages.append({
            "role": "user",
            "content": [
                {"type": "text", "text": "ÃœrÃ¼n gÃ¶rseli analiz et ve e-ticaret aÃ§Ä±klamasÄ± oluÅŸtur."},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{encoded}"}}
            ]
        })

    messages.append({"role": "user", "content": user_msg})

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.25,
            max_tokens=1800,
        )
        return resp.choices[0].message.content

    except Exception as e:
        print("E-ticaret GPT hatasÄ±:", e)
        return "E-Ticaret yanÄ±tÄ± oluÅŸturulamadÄ±."


# ------------------------------------------------------------
# DanÄ±ÅŸmanlÄ±k Prompt Ä°ÅŸleyici
# ------------------------------------------------------------
def consult_process_prompt(user_msg: str, img_bytes: Optional[bytes]) -> str:
    client = get_gpt_client()
    if not client:
        return "GPT hizmeti ÅŸu anda kullanÄ±lamÄ±yor."

    messages = [
        {"role": "system", "content": system_prompt_consulting()},
        {"role": "user", "content": user_msg},
    ]

    # DanÄ±ÅŸmanlÄ±k modunda gÃ¶rsel iÅŸleme genelde gerekmez,
    # ama kullanÄ±cÄ± 'bu tabloyu analiz et' derse destek olur.
    if img_bytes is not None:
        try:
            encoded = base64.b64encode(img_bytes).decode("utf-8")
            messages.append(
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Bu gÃ¶rselde analiz edilecek veri olabilir. Ä°Ã§gÃ¶rÃ¼ Ã§Ä±kar."},
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{encoded}"}}
                    ]
                }
            )
        except:
            pass

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=messages,
            temperature=0.2,
            max_tokens=2000,
        )
        return resp.choices[0].message.content

    except Exception as e:
        print("DanÄ±ÅŸmanlÄ±k GPT hatasÄ±:", e)
        return "DanÄ±ÅŸmanlÄ±k analizi yapÄ±lamadÄ±."


# ------------------------------------------------------------
# Router â€” Hangi model kullanÄ±lacak?
# ------------------------------------------------------------
def run_specialized_chat(mode: str, message: str, img_bytes: Optional[bytes]) -> str:
    """
    mode:
      - 'ecom'
      - 'consult'
    """
    if mode == "ecom":
        return ecommerce_process_prompt(message, img_bytes)

    if mode == "consult":
        return consult_process_prompt(message, img_bytes)

    return "GeÃ§ersiz mod."
# ============================================================
# A7-5 â€” ANA UI ROUTER (Gemini + GPT-4o entegrasyonu)
# ============================================================

def run_general_chat_gemini(user_msg: str, img_bytes: Optional[bytes]):
    """Genel Chat â†’ Gemini 1.5 Pro / Flash"""
    if not GEMINI_API_KEY:
        return "Gemini API anahtarÄ± bulunamadÄ±."

    model_name = "gemini-1.5-pro"   # en geliÅŸmiÅŸi
    payload = {
        "contents": [
            {
                "parts": [{"text": user_msg}]
            }
        ]
    }

    # GÃ¶rsel eklendiyse
    if img_bytes:
        b64 = base64.b64encode(img_bytes).decode("utf-8")
        payload["contents"][0]["parts"].append(
            {"inline_data": {"mime_type": "image/png", "data": b64}}
        )

    try:
        resp = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={GEMINI_API_KEY}",
            json=payload,
            timeout=20,
        )
        data = resp.json()
        return data["candidates"][0]["content"]["parts"][0]["text"]
    except Exception as e:
        print("Gemini hata:", e)
        return "Gemini yanÄ±t Ã¼retirken sorun oluÅŸtu."


# ============================================================
# A7-5 â€” CHAT UI + YÃ–NLENDÄ°RME BLOÄU
# ============================================================

def chat_interface(mode: str):
    """
    mode:
      - "general"   â†’ Gemini
      - "ecom"      â†’ GPT-4o
      - "consult"   â†’ GPT-4o
    """
    inject_voice_js()

    # BaÅŸlÄ±k
    if mode == "general":
        st.markdown("### ğŸ’¬ Genel Chat (Gemini 1.5 Pro)")
    elif mode == "ecom":
        st.markdown("### ğŸ›’ Qelyon AI â€” E-Ticaret AsistanÄ± (GPT-4o)")
    else:
        st.markdown("### ğŸ’¼ Qelyon AI â€” DanÄ±ÅŸmanlÄ±k AsistanÄ± (GPT-4o)")

    st.caption("Mesaj yazabilir, sesle giriÅŸ yapabilir veya gÃ¶rsel ekleyebilirsin.")

    # KonuÅŸma geÃ§miÅŸi
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # ------------------------------------------------------------
    # '+' BUTONU â†’ DOSYA EKLE PANELÄ°
    # ------------------------------------------------------------
    uibar = st.container()
    with uibar:
        col_a, col_b = st.columns([0.12, 0.88])

        with col_a:
            if st.button("â•", key="add_file2", help="Dosya / gÃ¶rsel ekle"):
                st.session_state.show_upload_panel = not st.session_state.show_upload_panel

        with col_b:
            if st.session_state.chat_image:
                st.caption("ğŸ“ GÃ¶rsel yÃ¼klendi, analiz edebilirim.")
            else:
                st.caption("Dosya ekleyebilirsin.")

    # Upload paneli
    if st.session_state.show_upload_panel:
        up = st.file_uploader(
            "GÃ¶rsel / Dosya Ekle", type=["png", "jpg", "jpeg", "webp", "pdf"]
        )
        if up:
            if up.type == "application/pdf":
                st.warning("PDF iÃ§erik desteÄŸi yakÄ±nda eklenecek (ÅŸimdilik yalnÄ±zca gÃ¶rsel).")
            else:
                st.session_state.chat_image = up.read()
                st.success("GÃ¶rsel baÅŸarÄ±yla eklendi.")
            st.session_state.show_upload_panel = False

    # ------------------------------------------------------------
    # CHAT INPUT
    # ------------------------------------------------------------
    user_msg = st.chat_input("Mesaj yazÄ±nâ€¦")
    if not user_msg:
        return

    # GeÃ§miÅŸe ekle
    st.session_state.chat_history.append({"role": "user", "content": user_msg})
    with st.chat_message("user"):
        st.write(user_msg)

    # GÃ¼venlik filtresi
    unsafe = moderate_content(user_msg)
    if unsafe:
        st.session_state.chat_history.append({"role": "assistant", "content": unsafe})
        with st.chat_message("assistant"):
            st.write(unsafe)
        return

    # Kimlik ve util intercept (genel chat hariÃ§)
    if mode in ["ecom", "consult"]:
        ident = custom_identity_interceptor(user_msg)
        util = custom_utility_interceptor(user_msg)

        if ident:
            st.session_state.chat_history.append({"role": "assistant", "content": ident})
            with st.chat_message("assistant"):
                st.write(ident)
            return

        if util:
            st.session_state.chat_history.append({"role": "assistant", "content": util})
            with st.chat_message("assistant"):
                st.write(util)
            return

    # ------------------------------------------------------------
    # MODEL MOTORUNA GÃ–NDER
    # ------------------------------------------------------------
    img_bytes = st.session_state.chat_image

    if mode == "general":
        response = run_general_chat_gemini(user_msg, img_bytes)

    elif mode == "ecom":
        response = run_specialized_chat("ecom", user_msg, img_bytes)

    elif mode == "consult":
        response = run_specialized_chat("consult", user_msg, img_bytes)

    else:
        response = "Mod bulunamadÄ±."

    # ------------------------------------------------------------
    # YANITI YAZDIR + GEÃ‡MÄ°ÅE EKLE
    # ------------------------------------------------------------
    with st.chat_message("assistant"):
        st.write(response)

    st.session_state.chat_history.append({"role": "assistant", "content": response})
# ============================================================
# A8 â€” ANA Ã‡ALIÅTIRMA BLOÄU (UI ROUTER)
# ============================================================

def main_app():
    inject_favicon()

    # ------------------------------
    # Tema seÃ§imi
    # ------------------------------
    col_t1, col_t2 = st.columns([10, 1])
    with col_t2:
        dark_mode = st.toggle("ğŸŒ™ / â˜€ï¸", value=True, key="theme_toggle")

    tema = get_theme(dark_mode)
    apply_apple_css(tema)

    # ------------------------------
    # Sidebar (konuÅŸma geÃ§miÅŸi + hazÄ±r promptlar)
    # ------------------------------
    sidebar_ui()

    # ------------------------------
    # Logo + BaÅŸlÄ±k alanÄ±
    # ------------------------------
    col_logo, col_title = st.columns([0.15, 0.85])
    with col_logo:
        logo_file = LOGO_DARK_PATH if dark_mode else LOGO_LIGHT_PATH
        try:
            st.image(logo_file, width=110)
        except:
            st.markdown("### Qelyon AI")

    with col_title:
        st.markdown(
            """
            <h1 style="margin-bottom:4px;">Qelyon AI StÃ¼dyo</h1>
            <p style="margin-top:0; font-size:0.95rem;">
                GÃ¶rsel dÃ¼zenleme, e-ticaret metinleri ve profesyonel danÄ±ÅŸmanlÄ±k
                sÃ¼reÃ§lerinde en gÃ¼Ã§lÃ¼ asistanÄ±n.
            </p>
            """,
            unsafe_allow_html=True
        )

    st.divider()

    # ------------------------------
    # 3 Mod (StÃ¼dyo / E-Ticaret / DanÄ±ÅŸmanlÄ±k / Genel Chat)
    # ------------------------------
    col_m1, col_m2, col_m3, col_m4 = st.columns(4)

    mode = st.session_state.app_mode

    with col_m1:
        if st.button("ğŸ“¸ StÃ¼dyo Modu", use_container_width=True,
                     type="primary" if mode=="studio" else "secondary"):
            st.session_state.app_mode = "studio"
            st.session_state.sonuc_gorseli = None
            st.rerun()

    with col_m2:
        if st.button("ğŸ›’ E-Ticaret AsistanÄ±", use_container_width=True,
                     type="primary" if mode=="ecom" else "secondary"):
            st.session_state.app_mode = "ecom"
            st.session_state.chat_image = None
            st.rerun()

    with col_m3:
        if st.button("ğŸ’¼ DanÄ±ÅŸmanlÄ±k AsistanÄ±", use_container_width=True,
                     type="primary" if mode=="consult" else "secondary"):
            st.session_state.app_mode = "consult"
            st.session_state.chat_image = None
            st.rerun()

    with col_m4:
        if st.button("ğŸ’¬ Genel Chat (Gemini)", use_container_width=True,
                     type="primary" if mode=="general" else "secondary"):
            st.session_state.app_mode = "general"
            st.session_state.chat_image = None
            st.rerun()

    st.divider()

    # ------------------------------
    # MOD YÃ–NLENDÄ°RME
    # ------------------------------
    if st.session_state.app_mode == "studio":
        run_studio_mode()            # Gemini Vision ile sahne dÃ¼zenleme

    elif st.session_state.app_mode == "general":
        chat_interface("general")    # Gemini 1.5 Pro

    elif st.session_state.app_mode == "ecom":
        chat_interface("ecom")       # GPT-4o

    elif st.session_state.app_mode == "consult":
        chat_interface("consult")    # GPT-4o

    else:
        st.error("Bilinmeyen mod seÃ§ildi.")

    # ------------------------------
    # Footer
    # ------------------------------
    st.markdown(
        "<div class='custom-footer'>Qelyon AI StÃ¼dyo Â© 2025 | Developed by Alper</div>",
        unsafe_allow_html=True,
    )


# ============================================================
# UygulamayÄ± Ã§alÄ±ÅŸtÄ±r
# ============================================================

try:
    main_app()
except Exception as e:
    print("MAIN ERROR:", traceback.format_exc())
    st.error("âš ï¸ Beklenmeyen bir hata oluÅŸtu. SayfayÄ± yenileyebilirsiniz.")
# ============================================================
# A9 â€” STÃœDYO MODU (Gemini Vision ile GÃ¶rsel Ä°ÅŸleme)
# ============================================================

import google.generativeai as genai
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

def run_studio_mode():
    st.markdown("### ğŸ“¤ ÃœrÃ¼n gÃ¶rselini yÃ¼kle")

    uploaded = st.file_uploader(
        "GÃ¶rsel seÃ§in",
        type=["png", "jpg", "jpeg", "webp"],
        label_visibility="collapsed",
    )

    if not uploaded:
        st.info("Bir Ã¼rÃ¼n gÃ¶rseli yÃ¼kleyin.")
        return

    # GÃ¶rseli oku
    try:
        raw = Image.open(uploaded)
        raw = ImageOps.exif_transpose(raw).convert("RGBA")
    except:
        st.error("âš  GÃ¶rsel okunamadÄ±.")
        return

    # Ã–nizleme
    col1, col2 = st.columns([1, 1])
    with col1:
        st.markdown("### ğŸ“Œ Orijinal")
        st.image(raw, width=360)

    with col2:
        st.markdown("### ğŸ¨ Tema / DÃ¼zenleme")

        tab_preset, tab_free = st.tabs(["ğŸ› HazÄ±r Temalar", "âœï¸ Serbest Prompt"])

        # ----------------------------
        # PRESET
        # ----------------------------
        with tab_preset:
            tema = st.selectbox(
                "Tema seÃ§:",
                [
                    "ğŸ§¹ Åeffaf Arka Plan",
                    "â¬œ Beyaz Arka Plan",
                    "â¬› Siyah Arka Plan",
                    "ğŸ¦ Bej Arka Plan",
                    "âœ¨ Profesyonel StÃ¼dyo",
                ],
            )

        # ----------------------------
        # SERBEST PROMPT
        # ----------------------------
        with tab_free:
            serbest = st.text_area(
                "Serbest sahne aÃ§Ä±klamasÄ±:",
                placeholder="Ã–rn: ÃœrÃ¼nÃ¼ merkezde bÄ±rak, yumuÅŸak gÃ¶lge ve aÃ§Ä±k gri degrade arka plan."
            )

        # ----------------------------
        # Ä°ÅLEM BAÅLAT
        # ----------------------------
        if st.button("ğŸš€ OluÅŸtur", type="primary"):
            with st.spinner("Gemini Vision sahneyi oluÅŸturuyor..."):

                try:
                    # GÃ¶rseli bytes olarak hazÄ±rla
                    img_bytes = BytesIO()
                    raw.save(img_bytes, format="PNG")
                    img_bytes.seek(0)

                    # --------------------------------------------
                    # PRESET PROMPT OLUÅTURUCU
                    # --------------------------------------------
                    if serbest.strip() == "":
                        if tema == "ğŸ§¹ Åeffaf Arka Plan":
                            prompt = """
                            Remove background COMPLETELY.
                            Preserve object edges, chains, textures.
                            No shadow, no artifacts. Transparent PNG output.
                            """

                        elif tema == "â¬œ Beyaz Arka Plan":
                            prompt = """
                            Replace background with PURE white (#ffffff).
                            Add soft professional shadow under product.
                            Keep product geometry unchanged.
                            """

                        elif tema == "â¬› Siyah Arka Plan":
                            prompt = """
                            Replace background with deep black (#000000).
                            Add soft realistic shadow.
                            High contrast professional studio style.
                            """

                        elif tema == "ğŸ¦ Bej Arka Plan":
                            prompt = """
                            Replace background with soft beige (#f5eedd).
                            Add smooth studio shadow.
                            """

                        elif tema == "âœ¨ Profesyonel StÃ¼dyo":
                            prompt = """
                            Create premium infinite studio background.
                            Soft white gradient, studio lighting, contact shadow + slight reflection.
                            Preserve product exactly.
                            """

                    else:
                        # SERBEST PROMPT
                        prompt = (
                            "Do not modify product shape, color or material. "
                            "High-end studio look. " + serbest
                        )

                    # --------------------------------------------
                    # GEMINI VISION Ä°STEÄÄ°
                    # --------------------------------------------
                    model = genai.GenerativeModel("gemini-1.5-flash")

                    out = model.generate_images(
                        prompt=prompt,
                        images=[img_bytes.getvalue()],
                        size="1024x1024"
                    )

                    # Gemini Ã§Ä±ktÄ±yÄ± al
                    result_bytes = out.images[0]

                    # SonuÃ§ kaydet
                    st.session_state.sonuc_gorseli = result_bytes

                except Exception as e:
                    st.error("âš  GÃ¶rsel oluÅŸturulurken bir hata oluÅŸtu.")
                    st.write(e)
                    return

                st.rerun()

    # ----------------------------
    # SONUÃ‡ EKRANI
    # ----------------------------
    if st.session_state.sonuc_gorseli:
        st.markdown("### âœ… SonuÃ§")
        st.image(st.session_state.sonuc_gorseli, width=380)

        colA, colB = st.columns(2)
        with colA:
            if st.button("ğŸ”„ Yeni iÅŸlem"):
                st.session_state.sonuc_gorseli = None
                st.rerun()
        with colB:
            st.download_button(
                "ğŸ“¥ PNG indir",
                data=st.session_state.sonuc_gorseli,
                file_name="qelyon_studio.png",
                mime="image/png",
            )
# ============================================================
# A10 â€” GENEL CHAT (Gemini 1.5 Pro + Flash)
# ============================================================

import google.generativeai as genai
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

def run_general_chat():
    st.markdown("### ğŸ’¬ Qelyon AI â€” Genel Chat")
    st.caption("Her konuda soru sorabilir, gÃ¶rsel yÃ¼kleyebilir veya yeni gÃ¶rsel oluÅŸturmasÄ±nÄ± isteyebilirsin.")

    # Oturum setup
    if "general_chat" not in st.session_state:
        st.session_state.general_chat = [
            {"role": "assistant", "content": "Merhaba! Ben Qelyon AI. NasÄ±l yardÄ±mcÄ± olabilirim?"}
        ]
    if "general_image" not in st.session_state:
        st.session_state.general_image = None
    if "general_upload_panel" not in st.session_state:
        st.session_state.general_upload_panel = False

    # ---------------------------
    # GeÃ§miÅŸ mesajlarÄ± gÃ¶ster
    # ---------------------------
    for msg in st.session_state.general_chat:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # ---------------------------
    # '+' â€” Dosya yÃ¼kleme butonu
    # ---------------------------
    bar = st.container()
    with bar:
        c1, c2 = st.columns([0.15, 0.85])
        with c1:
            if st.button("â•", key="general_add_file", help="Dosya veya gÃ¶rsel ekle"):
                st.session_state.general_upload_panel = not st.session_state.general_upload_panel

        with c2:
            if st.session_state.general_image:
                st.caption("ğŸ“ Bir gÃ¶rsel yÃ¼klÃ¼. Analiz isteyebilirsin.")

        # YÃ¼kleme paneli aÃ§Ä±ldÄ±ysa:
        if st.session_state.general_upload_panel:
            up = st.file_uploader("GÃ¶rsel yÃ¼kle", type=["png", "jpg", "jpeg", "webp"])
            if up:
                st.session_state.general_image = up.read()
                st.session_state.general_upload_panel = False
                st.success("GÃ¶rsel yÃ¼klendi! Åimdi analiz isteyebilirsin.")
                st.rerun()

    # ---------------------------
    # Mesaj Input
    # ---------------------------
    message = st.chat_input("Mesaj yazÄ±n...")

    if not message:
        return

    # KullanÄ±cÄ± mesajÄ± ekle
    st.session_state.general_chat.append({"role": "user", "content": message})
    with st.chat_message("user"):
        st.write(message)

    # ---------------------------
    # 1 â€” KullanÄ±cÄ± gÃ¶rsel oluÅŸturmayÄ± istiyor mu?
    # ---------------------------
    wants_image = any(w in message.lower() for w in [
        "gÃ¶rsel oluÅŸtur",
        "resim oluÅŸtur",
        "image generate",
        "bir gÃ¶rsel yap",
        "fotoÄŸraf Ã¼ret",
        "ai gÃ¶rsel oluÅŸtur"
    ])

    # ---------------------------
    # 2 â€” KullanÄ±cÄ± gÃ¶rsel yÃ¼klemiÅŸ mi?
    # ---------------------------
    has_user_image = st.session_state.general_image is not None

    # ---------------------------
    # GEMINI MODELLERÄ°
    # ---------------------------
    gemini_flash = genai.GenerativeModel("gemini-1.5-flash")
    gemini_pro = genai.GenerativeModel("gemini-1.5-pro")

    # ========================================================
    #   DURUM 1 â†’ GÃ–RSEL OLUÅTURMA
    # ========================================================
    if wants_image:
        with st.chat_message("assistant"):
            st.write("ğŸ¨ YÃ¼ksek kaliteli bir gÃ¶rsel oluÅŸturuyorum...")

        try:
            out = gemini_pro.generate_images(
                prompt=message,
                size="1024x1024"
            )

            img_bytes = out.images[0]

            with st.chat_message("assistant"):
                st.image(img_bytes, caption="OluÅŸturulan GÃ¶rsel")
                st.session_state.general_chat.append({
                    "role": "assistant",
                    "content": "Ä°ÅŸte oluÅŸturduÄŸun gÃ¶rsel!"
                })

            return

        except Exception as e:
            with st.chat_message("assistant"):
                st.error("âš  GÃ¶rsel oluÅŸturulamadÄ±.")
                st.write(e)
            return

    # ========================================================
    #   DURUM 2 â†’ GÃ–RSEL ÃœZERÄ°NDEN ANALÄ°Z / AÃ‡IKLAMA
    # ========================================================
    if has_user_image:
        try:
            img = st.session_state.general_image

            out = gemini_pro.generate_content(
                contents=[
                    {"mime_type": "image/png", "data": img},
                    {"text": f"Bu gÃ¶rseli analiz et ve kullanÄ±cÄ± mesajÄ±na gÃ¶re cevap Ã¼ret: {message}"}
                ]
            )

            answer = out.text

        except Exception as e:
            answer = "âš  GÃ¶rsel analizinde bir hata oluÅŸtu."
            print(e)

        with st.chat_message("assistant"):
            st.write(answer)

        st.session_state.general_chat.append({"role": "assistant", "content": answer})
        return

    # ========================================================
    #   DURUM 3 â†’ NORMAL SOHBET (GEMINI 1.5 PRO)
    # ========================================================
    try:
        response = gemini_pro.generate_text(message)
        answer = response.text
    except:
        answer = "âš  YanÄ±t Ã¼retilemedi (Gemini)."

    with st.chat_message("assistant"):
        st.write(answer)

    st.session_state.general_chat.append({"role": "assistant", "content": answer})
