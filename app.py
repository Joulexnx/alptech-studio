# ==========================================================
# QELYON AI STÃœDYO â€” FINAL v8
# Gemini Vision â€¢ Gemini Flash â€¢ Gemini 1.5 Pro â€¢ GPT-4o Hibrit Sistem
# ==========================================================

from __future__ import annotations

import os
import io
import re
import base64
import traceback
from datetime import datetime
from zoneinfo import ZoneInfo
from typing import Literal

import requests
import streamlit as st
from PIL import Image, ImageOps, ImageFilter, ImageChops, ImageDraw

# ==========================================================
# ğŸ” API KEYS
# ==========================================================
OPENAI_API_KEY = st.secrets.get("OPENAI_API_KEY", None)
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", None)
WEATHER_API_KEY = st.secrets.get("WEATHER_API_KEY", None)

GPT_MODEL = st.secrets.get("OPENAI_MODEL", "gpt-4o")
GEMINI_TEXT_MODEL = "gemini-1.5-pro"
GEMINI_VISION_MODEL = "gemini-1.5-flash"

if not OPENAI_API_KEY:
    st.error("âš ï¸ OPENAI_API_KEY eksik. GPT modlarÄ± Ã§alÄ±ÅŸmaz.")

if not GEMINI_API_KEY:
    st.error("âš ï¸ GEMINI_API_KEY eksik. Gemini modlarÄ± Ã§alÄ±ÅŸmaz.")

# ==========================================================
# ğŸ¨ LOGO & FAVICON
# ==========================================================
LOGO_LIGHT = "QelyonAIblack.png"
LOGO_DARK = "QelyonAIwhite.png"
FAVICON = "favicn.png"

st.set_page_config(
    page_title="Qelyon AI StÃ¼dyo",
    page_icon=FAVICON,
    layout="wide",
)

# ==========================================================
# ğŸ¨ THEME ENGINE
# ==========================================================
def get_theme(is_dark: bool):
    accent = "#6C47FF"
    if is_dark:
        return {
            "bg": "#050509",
            "text": "#FFFFFF",
            "sub": "#A8A8A8",
            "input": "#111111",
            "card": "rgba(255,255,255,0.05)",
            "border": "rgba(255,255,255,0.1)",
            "accent": accent,
        }
    else:
        return {
            "bg": "#F5F5FB",
            "text": "#0F172A",
            "sub": "#444444",
            "input": "#FFFFFF",
            "card": "rgba(255,255,255,0.85)",
            "border": "rgba(0,0,0,0.1)",
            "accent": accent,
        }

def apply_theme_css(t):
    st.markdown(
        f"""
        <style>
        body, .stApp {{
            background: {t['bg']} !important;
            color: {t['text']} !important;
        }}
        .stTextInput>div>div>input,
        textarea {{
            background: {t['input']} !important;
            color: {t['text']} !important;
            border-radius: 12px !important;
            border: 1px solid {t['border']} !important;
        }}
        [data-testid="stChatMessage"] {{
            background: {t['card']};
            border: 1px solid {t['border']};
            border-radius: 14px;
            padding: 10px 14px;
            margin-bottom: 10px;
        }}
        .stButton>button {{
            background: {t['accent']} !important;
            border-radius: 999px !important;
            color: white !important;
            font-weight: 600 !important;
        }}
        </style>
        """,
        unsafe_allow_html=True,
    )

# ==========================================================
# ğŸŒ™ Tema
# ==========================================================
col_a, col_b = st.columns([10,1])
with col_b:
    dark = st.toggle("ğŸŒ™ / â˜€ï¸", value=True)

THEME = get_theme(dark)
apply_theme_css(THEME)

# ==========================================================
# ğŸ§  GLOBAL SESSION SETUP
# ==========================================================
if "app_mode" not in st.session_state:
    st.session_state.app_mode = "ğŸ“¸ StÃ¼dyo Modu"

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "chat_image" not in st.session_state:
    st.session_state.chat_image = None

if "studio_result" not in st.session_state:
    st.session_state.studio_result = None
# ==========================================================
# A2 â€” API CLIENTS â€¢ GEMINI + GPT â€¢ UTILITY FONKSÄ°YONLARI
# ==========================================================

# ---------------------------
# ğŸ”¥ Gemini Client (Google AI)
# ---------------------------
import google.generativeai as genai

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    genai.configure(api_key="")  # boÅŸ da olsa initialize eder

def gemini_text(prompt: str):
    """Gemini 1.5 Pro ile metin Ã¼retimi"""
    try:
        model = genai.GenerativeModel(GEMINI_TEXT_MODEL)
        resp = model.generate_content(prompt)
        return resp.text
    except Exception as e:
        print("Gemini text error:", e)
        return "Gemini ÅŸu anda yanÄ±t veremiyor."

def gemini_vision(prompt: str, image_bytes: bytes):
    """Gemini Vision (Flash) ile gÃ¶rsel analiz"""
    try:
        model = genai.GenerativeModel(GEMINI_VISION_MODEL)
        img_data = {"mime_type": "image/png", "data": image_bytes}
        resp = model.generate_content([prompt, img_data])
        return resp.text
    except Exception as e:
        print("Gemini vision error:", e)
        return "GÃ¶rsel analizinde bir hata oluÅŸtu."

def gemini_generate_image(prompt: str, size="1024x1024"):
    """
    Gemini Flash Image ile gÃ¶rsel Ã¼retimi.
    Genel Chat modunda: logo, fotoÄŸraf, sahne vs. Ã¼retmek iÃ§in kullanÄ±lÄ±r.
    """
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        result = model.generate_image(prompt=prompt, size=size)
        return result._image  # bytes
    except Exception as e:
        print("Gemini image error:", e)
        return None


# ---------------------------
# ğŸ¤– GPT-4o Client
# ---------------------------
from openai import OpenAI
GPT = OpenAI(api_key=OPENAI_API_KEY)

def gpt_chat(messages: list[dict], model: str = GPT_MODEL):
    """
    GPT-4o tabanlÄ± sohbet motoru (E-ticaret & DanÄ±ÅŸmanlÄ±k iÃ§in)
    """
    try:
        res = GPT.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.2,
            max_tokens=1500,
        )
        return res.choices[0].message.content
    except Exception as e:
        print("GPT error:", e)
        return "GPT sistemi ÅŸu anda cevap veremiyor."


# ---------------------------
# âš¡ MODEL ROUTER (Mod seÃ§imine gÃ¶re motor)
# ---------------------------
def model_router(mode: str):
    """
    MODE â†’ MODEL
    ğŸ’¬ Genel Chat =====> Gemini 1.5 Pro
    ğŸ›’ E-Ticaret ======> GPT-4o
    ğŸ’¼ DanÄ±ÅŸmanlÄ±k =====> GPT-4o
    """
    if mode == "GENERAL_CHAT":
        return "gemini"
    if mode == "ECOM":
        return "gpt"
    if mode == "CONSULT":
        return "gpt"
    return "gemini"


# ==========================================================
# ğŸ“… ZAMAN / TARÄ°H SERVÄ°SLERÄ°
# ==========================================================
def get_tr_time():
    try:
        r = requests.get("http://worldtimeapi.org/api/timezone/Europe/Istanbul")
        dt = r.json().get("datetime")
        return datetime.fromisoformat(dt)
    except:
        return datetime.now(ZoneInfo("Europe/Istanbul"))

def time_answer():
    now = get_tr_time()
    return f"BugÃ¼n {now.strftime('%d.%m.%Y')} â€” Saat {now.strftime('%H:%M')}"


# ==========================================================
# ğŸŒ¦ HAVA DURUMU SERVÄ°SÄ°
# ==========================================================
def get_coords(city: str):
    try:
        url = (
            f"http://api.openweathermap.org/geo/1.0/direct?"
            f"q={city},TR&limit=1&appid={WEATHER_API_KEY}"
        )
        r = requests.get(url)
        data = r.json()
        if not data:
            return None
        return data[0]["lat"], data[0]["lon"]
    except:
        return None

def get_weather(city: str):
    coords = get_coords(city)
    if not coords:
        return f"{city} iÃ§in konum bulunamadÄ±."

    lat, lon = coords
    try:
        url = (
            f"https://api.openweathermap.org/data/2.5/weather?"
            f"lat={lat}&lon={lon}&appid={WEATHER_API_KEY}&units=metric&lang=tr"
        )
        r = requests.get(url).json()

        desc = r["weather"][0]["description"].capitalize()
        temp = r["main"]["temp"]
        hum = r["main"]["humidity"]
        wind = r["wind"]["speed"]

        return (
            f"ğŸ“ **{city.title()}**\n"
            f"ğŸŒ¡ï¸ SÄ±caklÄ±k: **{temp:.1f}Â°C**\n"
            f"â˜ï¸ Hava: **{desc}**\n"
            f"ğŸ’§ Nem: **%{hum}**\n"
            f"ğŸƒ RÃ¼zgar: **{wind} m/s**"
        )
    except:
        return "Hava durumu alÄ±namadÄ±."


# ==========================================================
# ğŸ›¡ GÃœVENLÄ°K FÄ°LTRESÄ°
# ==========================================================
BAD_WORDS = [
    r"(?i)orospu", r"(?i)siktir", r"(?i)amk",
    r"(?i)tecavÃ¼z", r"(?i)intihar", r"(?i)bomba yap",
]

def moderate_text(msg: str) -> str | None:
    """Mesaj uygunsuzsa engelle."""
    for pat in BAD_WORDS:
        if re.search(pat, msg):
            return "Bu isteÄŸe gÃ¼venlik nedeniyle yanÄ±t veremiyorum. ğŸ™"
    return None
# ==========================================================
# A3 â€” STÃœDYO MODU â€¢ GÃ–RSEL Ä°ÅLEME (GEMINI + LOCAL)
# ==========================================================

from PIL import Image, ImageOps, ImageFilter, ImageDraw, ImageChops


# ---------------------------------------
# ğŸ§¼ 1) LOKAL ARKA PLAN KALDIRMA (HQ MASKING)
# ---------------------------------------
def remove_bg_local(image: Image.Image) -> Image.Image:
    """
    ÃœrÃ¼nÃ¼ fotoÄŸraftan lokal threshold + mask algoritmasÄ± ile ayÄ±rÄ±r.
    Gemini Vision henÃ¼z 'image edit' yapamadÄ±ÄŸÄ± iÃ§in
    en stabil ve hÄ±zlÄ± yÃ¶ntem budur.
    """
    if image.mode != "RGBA":
        image = image.convert("RGBA")

    gray = image.convert("L")

    # YÃ¼ksek threshold â†’ parlak arka plan silinir
    mask = gray.point(lambda p: 255 if p > 240 else 0)

    result = Image.new("RGBA", image.size)
    result.paste(image, (0, 0), mask)
    return result


# ---------------------------------------
# ğŸ› 2) ÃœRÃœNÃœ KARE TUVALE MERKEZE YERLEÅTÄ°RME
# ---------------------------------------
def center_on_canvas(img: Image.Image, size=1024) -> Image.Image:
    canvas = Image.new("RGBA", (size, size), (0, 0, 0, 0))

    obj = img.copy()
    obj.thumbnail((size * 0.84, size * 0.84), Image.Resampling.LANCZOS)

    x = (size - obj.width) // 2
    y = (size - obj.height) // 2

    canvas.paste(obj, (x, y), obj)
    return canvas


# ---------------------------------------
# ğŸŒ“ 3) PROFESYONEL TEMAS GÃ–LGESÄ°
# ---------------------------------------
def make_contact_shadow(alpha: Image.Image, intensity=150):
    """ÃœrÃ¼nÃ¼n altÄ±na ticari stÃ¼dyo tarzÄ± soft shadow Ã¼retir."""
    a = alpha.convert("L")
    box = a.getbbox()
    if not box:
        return Image.new("L", a.size, 0)

    w = box[2] - box[0]
    h = int((box[3] - box[1]) * 0.22)

    shadow = Image.new("L", (w, h), 0)
    draw = ImageDraw.Draw(shadow)
    draw.ellipse((0, 0, w, h), fill=intensity)
    shadow = shadow.filter(ImageFilter.GaussianBlur(radius=int(h * 0.45)))

    mask = Image.new("L", a.size, 0)
    mask.paste(shadow, (box[0], box[3] - h // 2))
    return mask


# ---------------------------------------
# ğŸŒ« 4) STÃœDYO REFLECTION (Soft Reflection)
# ---------------------------------------
def make_reflection(img: Image.Image, fade=230):
    """Alt kÄ±sÄ±mda premium stÃ¼dyo refleks efekti Ã¼retir."""
    a = img.split()[3]
    box = a.getbbox()
    if not box:
        return Image.new("RGBA", img.size, (0, 0, 0, 0))

    crop = img.crop(box)
    flip = ImageOps.flip(crop)

    grad = Image.linear_gradient("L").resize((1, flip.height))
    grad = grad.point(lambda p: int(p * (fade / 255)))
    grad = grad.resize(flip.size)

    flip.putalpha(grad)

    out = Image.new("RGBA", img.size, (0, 0, 0, 0))
    out.paste(flip, (box[0], box[3] + 6), flip)
    return out


# ---------------------------------------
# ğŸ¨ 5) TEMA KOMPOZÄ°T MOTORU
# ---------------------------------------
def compose_scene(cut: Image.Image, bg_color: str, reflection=True, shadow=True):
    size = 1024
    obj = center_on_canvas(cut, size)
    alpha = obj.split()[3]

    colors = {
        "white": (255, 255, 255, 255),
        "black": (0, 0, 0, 255),
        "beige": (245, 240, 222, 255),
    }

    bg = Image.new("RGBA", (size, size), colors.get(bg_color, (255, 255, 255, 255)))
    final = Image.new("RGBA", (size, size), (0, 0, 0, 0))
    final.alpha_composite(bg)

    if shadow:
        sh_mask = make_contact_shadow(alpha)
        sh = Image.new("RGBA", (size, size), (0, 0, 0, 0))
        sh.putalpha(sh_mask)
        final.alpha_composite(sh)

    if reflection:
        ref = make_reflection(obj)
        final.alpha_composite(ref)

    final.alpha_composite(obj)
    return final


# ---------------------------------------
# âœ¨ 6) GEMINI â€” AI SAHNE OLUÅTURMA
# ---------------------------------------
def gemini_edit_scene(prompt: str, product_image_bytes: bytes):
    """
    ÃœrÃ¼nÃ¼ bozmadan; sadece arka planÄ± AI ile profesyonel olarak yeniden tasarlar.
    Gemini Flash Image modeli ile Ã§alÄ±ÅŸÄ±r.
    """
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")

        img_dict = {
            "mime_type": "image/png",
            "data": product_image_bytes,
        }

        full_prompt = (
            "You are a professional commercial product photographer. "
            "Replace ONLY the background. "
            "Do NOT modify the product (color, texture, geometry). "
            "Generate a clean, studio-grade, elegant scene.\n"
            f"Background style: {prompt}"
        )

        result = model.generate_image(
            prompt=full_prompt,
            image=img_dict,
            size="1024x1024",
        )

        return result._image  # PNG bytes

    except Exception as e:
        print("Gemini Edit Scene Error:", e)
        return None


# ---------------------------------------
# ğŸ— 7) HAZIR TEMA PRESETLERÄ°
# ---------------------------------------
PRESETS = {
    "ğŸ§¹ Åeffaf Arka Plan": "transparent",
    "â¬œ Beyaz Arka Plan": "white",
    "â¬› Siyah Arka Plan": "black",
    "ğŸ¦ Bej Arka Plan": "beige",
    "âœ¨ Profesyonel StÃ¼dyo": "pro",
}

def apply_preset(img: Image.Image, preset: str):
    """
    KullanÄ±cÄ±nÄ±n seÃ§tiÄŸi hazÄ±r temayÄ± uygular.
    """
    cut = remove_bg_local(img)

    if preset == "transparent":
        return cut

    if preset == "white":
        return compose_scene(cut, "white", reflection=False)

    if preset == "black":
        return compose_scene(cut, "black", reflection=False)

    if preset == "beige":
        return compose_scene(cut, "beige", reflection=False)

    if preset == "pro":
        return compose_scene(cut, "white", reflection=True)

    return cut
# ==========================================================
# A4 â€” GENEL CHAT MOTORU (GEMINI 1.5 PRO)
# ==========================================================

def gemini_general_chat(user_message: str, user_image: bytes | None):
    """
    Genel Chat (ğŸ’¬) iÃ§in tam sohbet motoru:
    - Gemini 1.5 Pro metin modeli
    - Vision input destekli
    - PDF / GÃ¶rsel / Dosya analizi
    - Ã‡oklu sohbet geÃ§miÅŸi desteÄŸi
    """

    try:
        # --- 1) Sohbet geÃ§miÅŸini Gemini formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r ---
        history = []
        for msg in st.session_state.chat_history[-25:]:
            if msg["role"] == "user":
                history.append({
                    "role": "user",
                    "parts": [msg["content"]]
                })
            else:
                history.append({
                    "role": "model",
                    "parts": [msg["content"]]
                })

        # --- 2) KullanÄ±cÄ±nÄ±n yeni mesajÄ± ---
        new_parts = [{"text": user_message}]

        # --- 3) EÄŸer gÃ¶rsel yÃ¼klÃ¼yse ekle ---
        if user_image:
            new_parts.append({
                "inline_data": {
                    "mime_type": "image/png",
                    "data": base64.b64encode(user_image).decode("utf-8")
                }
            })

        user_turn = {
            "role": "user",
            "parts": new_parts
        }

        full_prompt = history + [user_turn]

        # --- 4) Gemini model ---
        model = genai.GenerativeModel("gemini-1.5-pro")
        response = model.generate_content(full_prompt)

        if hasattr(response, "text"):
            return response.text

        return "Bir yanÄ±t Ã¼retemedim."

    except Exception as e:
        print("General Chat Error:", e)
        return "ğŸ’¥ ÃœzgÃ¼nÃ¼m, ÅŸu anda genel chat yanÄ±t veremiyor."


# ==========================================================
# A4 â€” GÃ–RSEL OLUÅTURMA MOTORU (Gemini Flash Image)
# ==========================================================

def gemini_generate_image(prompt: str, size: str = "1024x1024"):
    """
    Gemini Flash image generator
    - DALLÂ·E benzeri yÃ¼ksek kaliteli Ã¼retim
    - Genel Chat iÃ§inde otomatik tetiklenir
    """
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        result = model.generate_image(
            prompt=prompt,
            size=size,
        )
        return result._image  # PNG bytes
    except Exception as e:
        print("Gemini Image Error:", e)
        return None


# ==========================================================
# A4 â€” GÃ–RSEL OLUÅTURMA Ä°STEÄÄ° ALGILAYICI (AUTO DETECT)
# ==========================================================

IMAGE_TRIGGER_WORDS = [
    "gÃ¶rsel oluÅŸtur", "resim oluÅŸtur", "foto Ã¼ret",
    "bir gÃ¶rsel Ã§iz", "image create", "generate image",
    "bana bir tasarÄ±m yap", "logo yap", "arka plan Ã¼ret",
]


def is_image_generation_request(msg: str) -> bool:
    msg = msg.lower()
    return any(t in msg for t in IMAGE_TRIGGER_WORDS)


# ==========================================================
# A4 â€” GENEL CHAT ANA HANDLER
# ==========================================================

def handle_general_chat(user_message: str):
    """
    Genel Chat UI â†’ Motor baÄŸlayÄ±cÄ±.
    Bu fonksiyon ÅŸunlarÄ± yapar:
        âœ” GÃ¶rsel Ã¼retim isteÄŸi algÄ±lar (Flash)
        âœ” Normal sohbeti Gemini 1.5 Proâ€™ya yollar
        âœ” GÃ¶rsel analiz destekler
        âœ” Sohbet geÃ§miÅŸini yÃ¶netir
    """

    # 1) KullanÄ±cÄ± mesajÄ±nÄ± geÃ§miÅŸe kaydet
    st.session_state.chat_history.append({
        "role": "user",
        "content": user_message
    })

    with st.chat_message("user"):
        st.write(user_message)

    # 2) KullanÄ±cÄ± gÃ¶rsel Ã¼retmek mi istiyor?
    if is_image_generation_request(user_message):
        with st.chat_message("assistant"):
            st.write("ğŸ¨ GÃ¶rsel oluÅŸturuluyor...")

        img_bytes = gemini_generate_image(user_message)

        if img_bytes:
            st.image(img_bytes, caption="âœ¨ Gemini 1.5 Flash tarafÄ±ndan Ã¼retildi", width=350)
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": "(GÃ¶rsel Ã¼retildi)"
            })
            return
        else:
            with st.chat_message("assistant"):
                st.write("âš ï¸ GÃ¶rsel oluÅŸturulamadÄ±, lÃ¼tfen tekrar deneyin.")
            return

    # 3) Normal metin + gÃ¶rsel analizi sohbeti
    ai_answer = gemini_general_chat(
        user_message,
        st.session_state.chat_image
    )

    with st.chat_message("assistant"):
        st.write(ai_answer)

    st.session_state.chat_history.append({
        "role": "assistant",
        "content": ai_answer
    })
# ==========================================================
# A5 â€” GPT SYSTEM TALÄ°MATI (E-Ticaret + DanÄ±ÅŸmanlÄ±k Persona)
# ==========================================================

def build_system_talimati(profile: Literal["ecom", "consult"]) -> str:

    if profile == "ecom":
        return """
Sen Qelyon AI'nÄ±n E-Ticaret UzmanÄ± modundasÄ±n.
GÃ¶revlerin:

1) ÃœrÃ¼n aÃ§Ä±klamasÄ± (SEO uyumlu, profesyonel, ikna edici)
2) ÃœrÃ¼nÃ¼n Ã¶ne Ã§Ä±kan 5 faydasÄ±nÄ± yaz
3) Kutu iÃ§eriÄŸi oluÅŸtur
4) Hedef kitle analizi yap
5) KullanÄ±m Ã¶nerileri Ã¼ret
6) ÃœrÃ¼ne Ã¶zel CTA (satÄ±n almaya yÃ¶nlendiren)
7) ÃœrÃ¼n gÃ¶rseli varsa analiz et, metne entegre et
8) ÃœrÃ¼n iÃ§in A/B testli baÅŸlÄ±k varyantlarÄ± oluÅŸtur
9) Trendyol iÃ§in akÄ±llÄ± etiket algoritmasÄ± Ã§alÄ±ÅŸtÄ±r
10) Fiyat psikolojisi optimizasyonu Ã¶nerileri ver
11) ÃœrÃ¼n varyantlarÄ±nÄ± belirle (renk, beden, kapasite, model)
12) MÃ¼ÅŸteri yorumlarÄ±nÄ± analiz edip memnuniyet/ÅŸikayet temalarÄ±nÄ± Ã§Ä±kar
13) Sosyal medya reklam metinleri Ã¼ret (Meta, TikTok, Instagram)
14) Marka hikÃ¢yesi yaz
15) Ä°Ã§erikleri TÃ¼rkÃ§e ve profesyonel bir tonda oluÅŸtur

DÄ°KKAT:
- Gereksiz uzunluk yok, doÄŸrudan ticari fayda odaklÄ± yaz.
- ÃœrÃ¼n gÃ¶rseli varsa mutlaka analiz ederek davran.
- PDF veya dokÃ¼man varsa iÃ§eriÄŸini iÅŸine dahil et.
- Qelyon AI kimliÄŸinden sapma: YASAK.
"""
    
    # ------------------------------------------------------

    if profile == "consult":
        return """
Sen Qelyon AI'nÄ±n DanÄ±ÅŸmanlÄ±k UzmanÄ± modundasÄ±n.
UzmanlÄ±k alanlarÄ±n:
- Ä°ÅŸ geliÅŸtirme
- Marka konumlandÄ±rma
- Finansal iyileÅŸtirme
- Operasyonel verimlilik
- Pazarlama stratejisi
- Dijital dÃ¶nÃ¼ÅŸÃ¼m
- SWOT + rakip analizi
- KPI Ã§Ä±karÄ±mÄ±
- Yol haritasÄ± oluÅŸturma

GÃ¶revlerin:
1) KullanÄ±cÄ±nÄ±n iÅŸ modelini analiz et
2) SektÃ¶re Ã¶zel strateji Ã¶ner
3) KPI ve hedef sistemi Ã§Ä±kar
4) SWOT analizi yap
5) AdÄ±m adÄ±m geliÅŸim planÄ± oluÅŸtur
6) GerektiÄŸinde gelir modeli Ã¶ner
7) Ä°ÅŸ fikri validasyonu yap
8) PDF veya dokÃ¼man varsa analiz et, Ã§Ä±ktÄ±ya dahil et
9) GÃ¶rsel varsa iÃ§gÃ¶rÃ¼ Ã¼ret (Ã¶r: maÄŸaza fotoÄŸrafÄ±, Ã¼rÃ¼n, afiÅŸ)

Kimlik:
â€œQelyon AI olarak, profesyonel danÄ±ÅŸmanlÄ±k ve veri destekli iÃ§gÃ¶rÃ¼lerle iÅŸ hedeflerine ulaÅŸmanÄ± hÄ±zlandÄ±rÄ±yorum.â€

Tarz:
- Kesin
- Analitik
- Stratejik
- Gereksiz hikÃ¢ye yok, tamamen iÅŸ odaklÄ±.
"""

    return "Qelyon AI sistem talimatÄ± uygulanamadÄ±."
# ==========================================================
# A5 â€” IDENTITY INTERCEPTOR (Qelyon AI KÄ°MLÄ°K SÄ°STEMÄ°)
# ==========================================================

def custom_identity_interceptor(msg: str) -> Optional[str]:
    msg_low = msg.lower()

    if any(x in msg_low for x in ["kimsin", "sen neysin", "kim yapt", "kim geliÅŸtirdi"]):
        return "Ben Qelyon AI'yÄ±m. Hibrit bir mimari kullanÄ±yorum: Gemini Vision + GPT-4o. Qelyon AI ekibi tarafÄ±ndan geliÅŸtirildim."

    if "openai" in msg_low:
        return "HayÄ±r, ben OpenAI deÄŸilim. GPT-4o teknolojisini kullanÄ±yorum ama Qelyon AI'ya Ã¶zel yeteneklerle geniÅŸletildim."

    if "ne iÅŸ yaparsÄ±n" in msg_low or "gÃ¶revin ne" in msg_low:
        return "Qelyon AI olarak, profesyonel danÄ±ÅŸmanlÄ±k ve veri destekli iÃ§gÃ¶rÃ¼lerle iÅŸ hedeflerine ulaÅŸmanÄ± hÄ±zlandÄ±rÄ±yorum."

    return None
# ==========================================================
# A5 â€” UTILITY INTERCEPTOR (Zaman + Hava + PDF + GÃ¶rsel)
# ==========================================================

def custom_utility_interceptor(msg: str) -> Optional[str]:
    m = msg.lower()

    # Saat
    if "saat" in m or "kaÃ§" in m:
        return time_answer()

    # Hava durumu
    if "hava" in m or "hava durumu" in m:
        city = DEFAULT_CITY
        return get_weather(city)

    # PDF otomatik algÄ±
    if st.session_state.chat_image and msg.strip() in ["pdf", "pdf analizi", "analiz et"]:
        try:
            import fitz  # PyMuPDF
            doc = fitz.open(stream=st.session_state.chat_image, filetype="pdf")
            text = ""
            for page in doc:
                text += page.get_text()

            return f"ğŸ“„ PDF Analizi:\n{text[:2000]}..."
        except:
            return "PDF iÃ§erÄŸi okunamadÄ±."

    return None
# ==========================================================
# A5 â€” GPT-4o ANA ASÄ°STAN MOTORU
# ==========================================================

def gpt_assistant(profile: Literal["ecom", "consult"]) -> str:
    try:
        system_msg = build_system_talimati(profile)

        msgs = [{"role": "system", "content": system_msg}]
        for m in st.session_state.chat_history[-20:]:
            msgs.append({
                "role": m["role"],
                "content": m["content"]
            })

        client = OpenAI(api_key=OPENAI_API_KEY)

        res = client.chat.completions.create(
            model="gpt-4o",
            messages=msgs,
            temperature=0.3,
            max_tokens=1800,
        )

        return res.choices[0].message.content

    except Exception as e:
        print("GPT Assist Error:", e)

        # Fallback
        return "Åu anda GPT-4o yanÄ±t veremiyor. BirkaÃ§ dakika sonra tekrar deneyin."
# ==========================================================
# A5 â€” GPT ASÄ°STANI UI ROUTER
# ==========================================================

def handle_gpt_assistant(profile: Literal["ecom", "consult"], user_message: str):
    if not user_message:
        return

    # 1) Kimlik veya yardÄ±mcÄ± intercept
    ident = custom_identity_interceptor(user_message)
    util = custom_utility_interceptor(user_message)

    if ident:
        with st.chat_message("assistant"): st.write(ident)
        st.session_state.chat_history.append({"role": "assistant", "content": ident})
        return

    if util:
        with st.chat_message("assistant"): st.write(util)
        st.session_state.chat_history.append({"role": "assistant", "content": util})
        return

    # 2) Normal GPT-4o cevabÄ±
    with st.chat_message("assistant"):
        with st.spinner("Qelyon AI dÃ¼ÅŸÃ¼nÃ¼yor..."):
            answer = gpt_assistant(profile)
            st.write(answer)

    st.session_state.chat_history.append({"role": "assistant", "content": answer})
# ==========================================================
# A6 â€” MOD SEÃ‡Ä°MÄ° + GENEL CHAT (Gemini) + GPT ASÄ°STAN UI
# ==========================================================

# BaÅŸta A1'de ÅŸunlarÄ±n tanÄ±mlÄ± olduÄŸunu varsayÄ±yorum:
# - st.session_state.mode  (varsayÄ±lan: "ğŸ“¸ StÃ¼dyo Modu")
# - st.session_state.chat_history
# - st.session_state.studio_result
# Bu bÃ¶lÃ¼m, sadece chat modlarÄ±nÄ± yÃ¶netir.


# ---------------------------------------------
# ğŸ”€ 1) ÃœÃ§ Modluk Ãœst MenÃ¼ (Genel / Ecom / Consult)
# ---------------------------------------------
def render_main_modes():
    st.markdown("### ğŸ¤– Qelyon AI Mod SeÃ§imi")

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button(
            "ğŸ’¬ Genel Chat (Gemini 1.5 Pro)",
            use_container_width=True,
            type="primary" if st.session_state.mode == "GENERAL_CHAT" else "secondary",
        ):
            st.session_state.mode = "GENERAL_CHAT"
            st.session_state.chat_history = [
                {
                    "role": "assistant",
                    "content": "Merhaba! Ben Qelyon AI. Bu modda Gemini 1.5 Pro ile genel sohbet, gÃ¶rsel analizi ve gÃ¶rsel oluÅŸturma yapabilirsin. âœ¨",
                }
            ]
            st.session_state.chat_image = None
            st.rerun()

    with col2:
        if st.button(
            "ğŸ›’ E-Ticaret AsistanÄ± (GPT-4o)",
            use_container_width=True,
            type="primary" if st.session_state.mode == "ECOM" else "secondary",
        ):
            st.session_state.mode = "ECOM"
            st.session_state.chat_history = [
                {
                    "role": "assistant",
                    "content": "E-Ticaret AsistanÄ± aktif! ÃœrÃ¼nÃ¼nle ilgili bilgileri paylaÅŸ, birlikte profesyonel aÃ§Ä±klamalar ve stratejiler oluÅŸturalÄ±m. ğŸ›’",
                }
            ]
            st.session_state.chat_image = None
            st.rerun()

    with col3:
        if st.button(
            "ğŸ’¼ DanÄ±ÅŸmanlÄ±k AsistanÄ± (GPT-4o)",
            use_container_width=True,
            type="primary" if st.session_state.mode == "CONSULT" else "secondary",
        ):
            st.session_state.mode = "CONSULT"
            st.session_state.chat_history = [
                {
                    "role": "assistant",
                    "content": "DanÄ±ÅŸmanlÄ±k AsistanÄ± aktif! Ä°ÅŸ modelini, hedeflerini ve sorunlarÄ±nÄ± anlat; sana stratejik bir yol haritasÄ± Ã§Ä±karacaÄŸÄ±m. ğŸ’¼",
                }
            ]
            st.session_state.chat_image = None
            st.rerun()

    st.divider()


# ---------------------------------------------
# ğŸ’¬ 2) GENEL CHAT UI (Gemini 1.5 Pro + Flash)
# ---------------------------------------------
def general_chat_ui():
    st.markdown("### ğŸ’¬ Qelyon AI â€” Genel Chat (Gemini)")
    st.caption("Gemini 1.5 Pro & Flash ile metin, gÃ¶rsel analizi ve gÃ¶rsel oluÅŸturma yapabilirsin.")

    # --- Mesaj geÃ§miÅŸi ---
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # --- Dosya yÃ¼kleme (gÃ¶rsel / pdf) ---
    upload = st.file_uploader(
        "GÃ¶rsel / PDF yÃ¼kle (isteÄŸe baÄŸlÄ±)",
        type=["png", "jpg", "jpeg", "webp", "pdf"],
        key="general_upload",
    )

    if upload is not None:
        file_bytes = upload.read()
        # Hem eski isim hem yeni isim uyumlu olsun diye ikisini de set ediyoruz
        st.session_state.chat_image = file_bytes
        st.session_state.uploaded_chat_image = file_bytes
        st.success("ğŸ“ Dosya yÃ¼klendi! MesajÄ±nda bu dosyadan bahsedebilirsin.")

    # --- KullanÄ±cÄ± mesajÄ± ---
    user_msg = st.chat_input("MesajÄ±nÄ± yaz...")

    if user_msg:
        # GÃ¼venlik filtresi
        mod = moderate_text(user_msg)
        st.session_state.chat_history.append({"role": "user", "content": user_msg})

        with st.chat_message("user"):
            st.write(user_msg)

        if mod:
            with st.chat_message("assistant"):
                st.write(mod)
            st.session_state.chat_history.append({"role": "assistant", "content": mod})
            return

        # Gemini tarafÄ±na yÃ¶nlendir
        handle_general_chat(user_msg)


# ---------------------------------------------
# ğŸ›’ 3) E-TÄ°CARET ASÄ°STANI UI (GPT-4o)
# ---------------------------------------------
def ecom_chat_ui():
    st.markdown("### ğŸ›’ Qelyon AI â€” E-Ticaret AsistanÄ± (GPT-4o)")
    st.caption("ÃœrÃ¼n aÃ§Ä±klamalarÄ±, SEO baÅŸlÄ±klar, etiketler ve kampanya metinleri iÃ§in kullan.")

    # Mesaj geÃ§miÅŸi
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Ä°steÄŸe baÄŸlÄ± gÃ¶rsel / pdf yÃ¼kleme
    upload = st.file_uploader(
        "ÃœrÃ¼n gÃ¶rseli veya PDF yÃ¼kle (opsiyonel)",
        type=["png", "jpg", "jpeg", "webp", "pdf"],
        key="ecom_upload",
    )
    if upload is not None:
        file_bytes = upload.read()
        st.session_state.chat_image = file_bytes
        st.session_state.uploaded_chat_image = file_bytes
        st.success("ğŸ“ Dosya yÃ¼klendi! ÃœrÃ¼n aÃ§Ä±klamasÄ±nda bu dosyaya referans verebilirsin.")

    user_msg = st.chat_input("ÃœrÃ¼n veya ihtiyacÄ±nÄ± anlat...")

    if user_msg:
        st.session_state.chat_history.append({"role": "user", "content": user_msg})
        with st.chat_message("user"):
            st.write(user_msg)

        handle_gpt_assistant("ecom", user_message=user_msg)


# ---------------------------------------------
# ğŸ’¼ 4) DANIÅMANLIK ASÄ°STANI UI (GPT-4o)
# ---------------------------------------------
def consult_chat_ui():
    st.markdown("### ğŸ’¼ Qelyon AI â€” DanÄ±ÅŸmanlÄ±k AsistanÄ± (GPT-4o)")
    st.caption("Ä°ÅŸ modeli, bÃ¼yÃ¼me stratejisi, KPI/OKR ve operasyonel verimlilik iÃ§in kullan.")

    # Mesaj geÃ§miÅŸi
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])

    # Opsiyonel dokÃ¼man/gÃ¶rsel yÃ¼kleme
    upload = st.file_uploader(
        "Rapor, PDF veya gÃ¶rsel yÃ¼kle (opsiyonel)",
        type=["png", "jpg", "jpeg", "webp", "pdf"],
        key="consult_upload",
    )
    if upload is not None:
        file_bytes = upload.read()
        st.session_state.chat_image = file_bytes
        st.session_state.uploaded_chat_image = file_bytes
        st.success("ğŸ“ Dosya yÃ¼klendi! Analiz yaparken bu dosyadan bahsedebilirsin.")

    user_msg = st.chat_input("Ä°ÅŸini veya sorunu anlat...")

    if user_msg:
        st.session_state.chat_history.append({"role": "user", "content": user_msg})
        with st.chat_message("user"):
            st.write(user_msg)

        handle_gpt_assistant("consult", user_message=user_msg)


# ---------------------------------------------
# ğŸš¦ 5) ANA ROUTER â€” Hangi chat UI Ã§alÄ±ÅŸacak?
# ---------------------------------------------
def run_assistant_router():
    # Ãœstte mod butonlarÄ±nÄ± Ã§iz
    render_main_modes()

    # Sonra seÃ§ilen moda gÃ¶re UI aÃ§
    if st.session_state.mode == "GENERAL_CHAT":
        general_chat_ui()

    elif st.session_state.mode == "ECOM":
        ecom_chat_ui()

    elif st.session_state.mode == "CONSULT":
        consult_chat_ui()

    # EÄŸer mode baÅŸka bir ÅŸey ise (Ã¶rneÄŸin ğŸ“¸ StÃ¼dyo Modu),
    # burada hiÃ§bir ÅŸey yapma; stÃ¼dyo kodun kendi bloÄŸunda Ã§alÄ±ÅŸsÄ±n.
    # ==========================================================
# A7 â€” ğŸ“¸ QELYON AI STÃœDYO MODU (FINAL v8)
# ==========================================================

def render_studio_mode():
    st.markdown("## ğŸ“¸ Qelyon AI â€” StÃ¼dyo Modu")
    st.caption("ÃœrÃ¼nlerin iÃ§in profesyonel arka plan, Ä±ÅŸÄ±k, gÃ¶lge ve sahne oluÅŸturma modu.")

    # ------------------------
    # 1) GÃ¶rsel yÃ¼kleme alanÄ±
    # ------------------------
    uploaded = st.file_uploader(
        "ğŸ¨ ÃœrÃ¼n fotoÄŸrafÄ±nÄ± yÃ¼kle",
        type=["png", "jpg", "jpeg", "webp"],
        key="studio_upload",
    )

    if uploaded is not None:
        img = Image.open(uploaded).convert("RGBA")
        st.image(img, caption="YÃ¼klenen GÃ¶rsel", width=350)
        st.session_state.studio_source = img

    # EÄŸer henÃ¼z gÃ¶rsel yoksa devam etme
    if "studio_source" not in st.session_state:
        st.info("BaÅŸlamak iÃ§in bir Ã¼rÃ¼n gÃ¶rseli yÃ¼kle.")
        return

    img = st.session_state.studio_source

    # ------------------------
    # 2) Preset seÃ§imleri
    # ------------------------
    st.markdown("### ğŸ› HazÄ±r Temalar")

    preset_name = st.selectbox(
        "Bir tema seÃ§:",
        list(PRESETS.keys()),
        index=0,
    )

    # ------------------------
    # 3) Profesyonel AI sahne oluÅŸturma
    # ------------------------
    st.markdown("### âœ¨ AI Sahne OluÅŸturma (Opsiyonel)")

    ai_prompt = st.text_area(
        "Profesyonel sahne (Ã¶rn: 'lÃ¼x stÃ¼dyo Ä±ÅŸÄ±ÄŸÄ±, soft shadow, minimal set')",
        placeholder="Buraya yazarsan Gemini Vision Ã¶zel sahne oluÅŸturur.",
    )

    generate_ai_scene = st.button("âœ¨ AI Sahne OluÅŸtur", type="primary")

    # ------------------------
    # 4) Ä°ÅŸlem butonu
    # ------------------------
    apply_preset_btn = st.button("ğŸ¨ TemayÄ± Uygula")

    result = None

    # ------------------------
    # 5) TemayÄ± uygula (lokal render)
    # ------------------------
    if apply_preset_btn:
        with st.spinner("TemanÄ±z iÅŸleniyor..."):
            result = apply_preset(img, PRESETS[preset_name])
            st.session_state.studio_result = result

    # ------------------------
    # 6) AI sahne oluÅŸtur
    # ------------------------
    if generate_ai_scene and ai_prompt.strip():
        with st.spinner("AI sahne oluÅŸturuluyor... (Gemini Vision)"):
            buffered = io.BytesIO()
            img.save(buffered, format="PNG")
            bytes_img = buffered.getvalue()

            ai_img_bytes = gemini_edit_scene(ai_prompt, bytes_img)

            if ai_img_bytes:
                result = Image.open(io.BytesIO(ai_img_bytes)).convert("RGBA")
                st.session_state.studio_result = result
            else:
                st.error("AI sahne oluÅŸturulamadÄ±. LÃ¼tfen yeniden deneyin.")

    # ------------------------
    # 7) SonuÃ§ gÃ¶rÃ¼ntÃ¼leme
    # ------------------------
    if st.session_state.studio_result is not None:
        st.markdown("### ğŸ“¤ Ã‡Ä±ktÄ±")

        st.image(st.session_state.studio_result, width=512)

        # Ä°ndirilebilir link
        output_buffer = io.BytesIO()
        st.session_state.studio_result.save(output_buffer, format="PNG")
        st.download_button(
            "ğŸ“¥ Ã‡Ä±ktÄ±yÄ± Ä°ndir (PNG)",
            data=output_buffer.getvalue(),
            file_name="qelyon_studio_output.png",
            mime="image/png",
        )
# ==========================================================
# A8 â€” ğŸ“„ PDF & ğŸ–¼ GÃ¶rsel OCR + Belge Analiz Motoru (Gemini 1.5 Pro)
# ==========================================================

import mimetypes

def guess_mime_type(filename: str, default: str = "application/octet-stream") -> str:
    """
    Dosya adÄ±na gÃ¶re MIME type tahmini.
    Ã–rn:
      - .pdf  -> application/pdf
      - .png  -> image/png
      - .jpg  -> image/jpeg
    """
    mime, _ = mimetypes.guess_type(filename)
    return mime or default


def gemini_analyze_document(
    file_bytes: bytes,
    filename: str,
    user_instruction: str = "Bu dosyayÄ± profesyonelce Ã¶zetle ve Ã¶nemli maddeleri Ã§Ä±kar.",
) -> str:
    """
    PDF, PNG, JPG gibi dosyalarÄ± Gemini 1.5 Pro ile okur (OCR + anlamlandÄ±rma).
    - PDF ise: iÃ§eriÄŸi okur, metni anlar, Ã¶zetler.
    - GÃ¶rsel ise: gÃ¶rsel Ã¼zerindeki yazÄ±larÄ± (OCR) + gÃ¶rsel iÃ§eriÄŸini analiz eder.
    """

    if not file_bytes:
        return "Dosya iÃ§eriÄŸi boÅŸ gÃ¶rÃ¼nÃ¼yor."

    mime_type = guess_mime_type(filename)

    # Gemini'ye gÃ¶nderilecek parÃ§a
    file_part = {
        "mime_type": mime_type,
        "data": file_bytes,
    }

    # Sistem promptu + kullanÄ±cÄ±nÄ±n talimatÄ±
    prompt = (
        "Sen Qelyon AI dokÃ¼man analiz uzmanÄ±sÄ±n. "
        "PDF, resim veya taranmÄ±ÅŸ belge iÃ§eriÄŸini dikkatlice okur, "
        "Ã¶nemli kÄ±sÄ±mlarÄ± net ve anlaÅŸÄ±lÄ±r bir ÅŸekilde Ã¶zetlersin. "
        "Maddeler halinde kritik baÅŸlÄ±klarÄ± ve aksiyon alÄ±nabilir Ã¶nerileri Ã§Ä±kar.\n\n"
        f"KullanÄ±cÄ± talimatÄ±: {user_instruction}"
    )

    try:
        model = genai.GenerativeModel(GEMINI_TEXT_MODEL)
        response = model.generate_content([prompt, file_part])

        if hasattr(response, "text") and response.text:
            return response.text.strip()

        return "Dosya analiz edildi fakat metin cevap Ã¼retilemedi."
    except Exception as e:
        print("Gemini Document Analyze Error:", e)
        return "Belge analizinde bir hata oluÅŸtu. LÃ¼tfen daha sonra tekrar dene."


# ----------------------------------------------------------
# A8 â€” ğŸ”Œ Genel Chat / DiÄŸer Modlarda KullanÄ±m Ã–rneÄŸi (opsiyonel)
# ----------------------------------------------------------

def analyze_uploaded_file_in_chat(user_message: str) -> str:
    """
    General Chat iÃ§inde:
      - KullanÄ±cÄ± PDF / gÃ¶rsel yÃ¼klediyse
      - 'bu pdfi Ã¶zetle', 'bu gÃ¶rseli analiz et', 'bu dosyayÄ± incele' gibi bir ÅŸey yazdÄ±ysa
    â†’ Bu fonksiyon Ã§aÄŸrÄ±lÄ±p Gemini belge analiz Ã§alÄ±ÅŸtÄ±rÄ±labilir.

    Bunu direkt general_chat_ui veya baÅŸka bir UI fonksiyonundan Ã§aÄŸÄ±rabilirsin.
    """

    if "chat_image" not in st.session_state or st.session_state.chat_image is None:
        return "Analiz edilecek yÃ¼klÃ¼ bir dosya bulamadÄ±m. LÃ¼tfen Ã¶nce bir PDF veya gÃ¶rsel yÃ¼kle."

    triggers = [
        "pdfi Ã¶zetle",
        "pdf'i Ã¶zetle",
        "pdf Ã¶zetle",
        "bu dosyayÄ± Ã¶zetle",
        "bu dosyayÄ± analiz et",
        "belgeyi analiz et",
        "dokÃ¼manÄ± analiz et",
        "bu gÃ¶rseli analiz et",
        "bu resmi analiz et",
        "dosyayÄ± incele",
    ]

    if not any(t in user_message.lower() for t in triggers):
        # KullanÄ±cÄ±nÄ±n isteÄŸi doÄŸrudan dokÃ¼man analizi deÄŸilse, normal chat akÄ±ÅŸÄ± devam edebilir.
        return ""

    # Buraya geldiÄŸimizde â†’ gerÃ§ekten belge analizi isteniyor
    file_bytes = st.session_state.chat_image
    filename = getattr(st.session_state, "chat_filename", "dosya")

    # KullanÄ±cÄ± talimatÄ± (isteÄŸe baÄŸlÄ± geliÅŸtirilebilir)
    user_instruction = user_message

    result = gemini_analyze_document(file_bytes, filename, user_instruction)
    return result
upload = st.file_uploader(
    "GÃ¶rsel / PDF / Dosya ekle",
    type=["png", "jpg", "jpeg", "webp", "pdf"],
    key="general_upload"
)

if upload:
    st.session_state.chat_image = upload.read()
    st.session_state.chat_filename = upload.name  # ğŸ”¹ A8 iÃ§in Ã¶nemli
    st.success("Dosya yÃ¼klendi!")
prompt = st.chat_input("Bir mesaj yaz...")

if prompt:
    # Ã¶nce dokÃ¼man analizi tetikleniyor mu diye bak
    doc_answer = analyze_uploaded_file_in_chat(prompt)
    if doc_answer:
        with st.chat_message("assistant"):
            st.write(doc_answer)
        st.session_state.chat_history.append({"role": "assistant", "content": doc_answer})
    else:
        # normal Gemini general chat akÄ±ÅŸÄ± (senin mevcut kodun)
        handle_general_chat(prompt)


